{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GOALS**:\n",
    "\n",
    "- Discover spark and use it locally on a small subset of images from the [fruits_360 dataset](https://www.kaggle.com/datasets/moltean/fruits).\n",
    "- Extract image features and reduce its dimensionality with PCA."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- 1. [Define paths and build a small subset of images to experiment with my local machine and avoid huge cost on the cloud.](#toc1_)    \n",
    "- 2. [Launch a Spark Session](#toc2_)    \n",
    "- 3. [Load Images](#toc3_)    \n",
    "- 4. [Build model for feature extraction and broadcast its weights.](#toc4_)    \n",
    "- 5. [Functions](#toc5_)    \n",
    "- 6. [Loading results computed locally with spark](#toc6_)    \n",
    "- 7. [Compare to not distributed computation based on tf and sklearn.](#toc7_)    \n",
    "- 8. [?](#toc8_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=true\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 09:51:14.711840: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-18 09:51:15.236535: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-18 09:51:15.238514: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-18 09:51:16.732699: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, element_at, split\n",
    "from pyspark.sql.functions import udf, pandas_udf, PandasUDFType\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.ml.feature import StandardScaler, PCA\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from typing import Iterator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  [&#9650;](#toc0_) <a id='toc1_'></a>Define paths and build a small subset of images to experiment with my local machine and avoid huge cost on the cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATH: /home/louberehc/OCR/projets/8_cloud_computing\n",
      "DATA_PATH: /home/louberehc/OCR/projets/8_cloud_computing/fruits_360\n",
      "RESULT_PATH: /home/louberehc/OCR/projets/8_cloud_computing/Results\n",
      "TRAIN_PATH: /home/louberehc/OCR/projets/8_cloud_computing/fruits_360/Training\n",
      "TEST_PATH: /home/louberehc/OCR/projets/8_cloud_computing/fruits_360/Test\n"
     ]
    }
   ],
   "source": [
    "PATH = os.getcwd()\n",
    "DATA_PATH = os.path.join(PATH ,'fruits_360')\n",
    "RESULT_PATH = os.path.join(PATH ,'Results')\n",
    "TRAIN_PATH = os.path.join(DATA_PATH , 'Training')\n",
    "TEST_PATH = os.path.join(DATA_PATH , 'Test')\n",
    "IMAGE_SUBSET_PATH = os.path.join(PATH, 'images_subset')\n",
    "\n",
    "if not os.path.exists(RESULT_PATH):\n",
    "    os.mkdir(RESULT_PATH)\n",
    "\n",
    "if not os.path.exists(IMAGE_SUBSET_PATH):\n",
    "    os.mkdir(IMAGE_SUBSET_PATH)\n",
    "\n",
    "print('PATH: '+ PATH \\\n",
    "      +'\\nDATA_PATH: '+  DATA_PATH \\\n",
    "      +'\\nRESULT_PATH: '+RESULT_PATH\n",
    "        +'\\nTRAIN_PATH: '+  TRAIN_PATH \\\n",
    "      +'\\nTEST_PATH: '+TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/home/louberehc/OCR/projets/8_cloud_computing/fruits_360/Training\u001b[0m\n",
      "├── \u001b[01;34mApple Braeburn\u001b[0m\n",
      "├── \u001b[01;34mApple Crimson Snow\u001b[0m\n",
      "├── \u001b[01;34mApple Golden 1\u001b[0m\n",
      "├── \u001b[01;34mApple Golden 2\u001b[0m\n",
      "├── \u001b[01;34mApple Golden 3\u001b[0m\n",
      "├── \u001b[01;34mApple Granny Smith\u001b[0m\n",
      "├── \u001b[01;34mApple Pink Lady\u001b[0m\n",
      "├── \u001b[01;34mApple Red 1\u001b[0m\n",
      "├── \u001b[01;34mApple Red 2\u001b[0m\n",
      "├── \u001b[01;34mApple Red 3\u001b[0m\n",
      "├── \u001b[01;34mApple Red Delicious\u001b[0m\n",
      "├── \u001b[01;34mApple Red Yellow 1\u001b[0m\n",
      "├── \u001b[01;34mApple Red Yellow 2\u001b[0m\n",
      "├── \u001b[01;34mApricot\u001b[0m\n",
      "├── \u001b[01;34mAvocado\u001b[0m\n",
      "├── \u001b[01;34mAvocado ripe\u001b[0m\n",
      "├── \u001b[01;34mBanana\u001b[0m\n",
      "├── \u001b[01;34mBanana Lady Finger\u001b[0m\n",
      "├── \u001b[01;34mBanana Red\u001b[0m\n",
      "├── \u001b[01;34mBeetroot\u001b[0m\n",
      "├── \u001b[01;34mBlueberry\u001b[0m\n",
      "├── \u001b[01;34mCactus fruit\u001b[0m\n",
      "├── \u001b[01;34mCantaloupe 1\u001b[0m\n",
      "├── \u001b[01;34mCantaloupe 2\u001b[0m\n",
      "├── \u001b[01;34mCarambula\u001b[0m\n",
      "├── \u001b[01;34mCauliflower\u001b[0m\n",
      "├── \u001b[01;34mCherry 1\u001b[0m\n",
      "├── \u001b[01;34mCherry 2\u001b[0m\n",
      "├── \u001b[01;34mCherry Rainier\u001b[0m\n",
      "├── \u001b[01;34mCherry Wax Black\u001b[0m\n",
      "├── \u001b[01;34mCherry Wax Red\u001b[0m\n",
      "├── \u001b[01;34mCherry Wax Yellow\u001b[0m\n",
      "├── \u001b[01;34mChestnut\u001b[0m\n",
      "├── \u001b[01;34mClementine\u001b[0m\n",
      "├── \u001b[01;34mCocos\u001b[0m\n",
      "├── \u001b[01;34mCorn\u001b[0m\n",
      "├── \u001b[01;34mCorn Husk\u001b[0m\n",
      "├── \u001b[01;34mCucumber Ripe\u001b[0m\n",
      "├── \u001b[01;34mCucumber Ripe 2\u001b[0m\n",
      "├── \u001b[01;34mDates\u001b[0m\n",
      "├── \u001b[01;34mEggplant\u001b[0m\n",
      "├── \u001b[01;34mFig\u001b[0m\n",
      "├── \u001b[01;34mGinger Root\u001b[0m\n",
      "├── \u001b[01;34mGranadilla\u001b[0m\n",
      "├── \u001b[01;34mGrape Blue\u001b[0m\n",
      "├── \u001b[01;34mGrapefruit Pink\u001b[0m\n",
      "├── \u001b[01;34mGrapefruit White\u001b[0m\n",
      "├── \u001b[01;34mGrape Pink\u001b[0m\n",
      "├── \u001b[01;34mGrape White\u001b[0m\n",
      "├── \u001b[01;34mGrape White 2\u001b[0m\n",
      "├── \u001b[01;34mGrape White 3\u001b[0m\n",
      "├── \u001b[01;34mGrape White 4\u001b[0m\n",
      "├── \u001b[01;34mGuava\u001b[0m\n",
      "├── \u001b[01;34mHazelnut\u001b[0m\n",
      "├── \u001b[01;34mHuckleberry\u001b[0m\n",
      "├── \u001b[01;34mKaki\u001b[0m\n",
      "├── \u001b[01;34mKiwi\u001b[0m\n",
      "├── \u001b[01;34mKohlrabi\u001b[0m\n",
      "├── \u001b[01;34mKumquats\u001b[0m\n",
      "├── \u001b[01;34mLemon\u001b[0m\n",
      "├── \u001b[01;34mLemon Meyer\u001b[0m\n",
      "├── \u001b[01;34mLimes\u001b[0m\n",
      "├── \u001b[01;34mLychee\u001b[0m\n",
      "├── \u001b[01;34mMandarine\u001b[0m\n",
      "├── \u001b[01;34mMango\u001b[0m\n",
      "├── \u001b[01;34mMango Red\u001b[0m\n",
      "├── \u001b[01;34mMangostan\u001b[0m\n",
      "├── \u001b[01;34mMaracuja\u001b[0m\n",
      "├── \u001b[01;34mMelon Piel de Sapo\u001b[0m\n",
      "├── \u001b[01;34mMulberry\u001b[0m\n",
      "├── \u001b[01;34mNectarine\u001b[0m\n",
      "├── \u001b[01;34mNectarine Flat\u001b[0m\n",
      "├── \u001b[01;34mNut Forest\u001b[0m\n",
      "├── \u001b[01;34mNut Pecan\u001b[0m\n",
      "├── \u001b[01;34mOnion Red\u001b[0m\n",
      "├── \u001b[01;34mOnion Red Peeled\u001b[0m\n",
      "├── \u001b[01;34mOnion White\u001b[0m\n",
      "├── \u001b[01;34mOrange\u001b[0m\n",
      "├── \u001b[01;34mPapaya\u001b[0m\n",
      "├── \u001b[01;34mPassion Fruit\u001b[0m\n",
      "├── \u001b[01;34mPeach\u001b[0m\n",
      "├── \u001b[01;34mPeach 2\u001b[0m\n",
      "├── \u001b[01;34mPeach Flat\u001b[0m\n",
      "├── \u001b[01;34mPear\u001b[0m\n",
      "├── \u001b[01;34mPear 2\u001b[0m\n",
      "├── \u001b[01;34mPear Abate\u001b[0m\n",
      "├── \u001b[01;34mPear Forelle\u001b[0m\n",
      "├── \u001b[01;34mPear Kaiser\u001b[0m\n",
      "├── \u001b[01;34mPear Monster\u001b[0m\n",
      "├── \u001b[01;34mPear Red\u001b[0m\n",
      "├── \u001b[01;34mPear Stone\u001b[0m\n",
      "├── \u001b[01;34mPear Williams\u001b[0m\n",
      "├── \u001b[01;34mPepino\u001b[0m\n",
      "├── \u001b[01;34mPepper Green\u001b[0m\n",
      "├── \u001b[01;34mPepper Orange\u001b[0m\n",
      "├── \u001b[01;34mPepper Red\u001b[0m\n",
      "├── \u001b[01;34mPepper Yellow\u001b[0m\n",
      "├── \u001b[01;34mPhysalis\u001b[0m\n",
      "├── \u001b[01;34mPhysalis with Husk\u001b[0m\n",
      "├── \u001b[01;34mPineapple\u001b[0m\n",
      "├── \u001b[01;34mPineapple Mini\u001b[0m\n",
      "├── \u001b[01;34mPitahaya Red\u001b[0m\n",
      "├── \u001b[01;34mPlum\u001b[0m\n",
      "├── \u001b[01;34mPlum 2\u001b[0m\n",
      "├── \u001b[01;34mPlum 3\u001b[0m\n",
      "├── \u001b[01;34mPomegranate\u001b[0m\n",
      "├── \u001b[01;34mPomelo Sweetie\u001b[0m\n",
      "├── \u001b[01;34mPotato Red\u001b[0m\n",
      "├── \u001b[01;34mPotato Red Washed\u001b[0m\n",
      "├── \u001b[01;34mPotato Sweet\u001b[0m\n",
      "├── \u001b[01;34mPotato White\u001b[0m\n",
      "├── \u001b[01;34mQuince\u001b[0m\n",
      "├── \u001b[01;34mRambutan\u001b[0m\n",
      "├── \u001b[01;34mRaspberry\u001b[0m\n",
      "├── \u001b[01;34mRedcurrant\u001b[0m\n",
      "├── \u001b[01;34mSalak\u001b[0m\n",
      "├── \u001b[01;34mStrawberry\u001b[0m\n",
      "├── \u001b[01;34mStrawberry Wedge\u001b[0m\n",
      "├── \u001b[01;34mTamarillo\u001b[0m\n",
      "├── \u001b[01;34mTangelo\u001b[0m\n",
      "├── \u001b[01;34mTomato 1\u001b[0m\n",
      "├── \u001b[01;34mTomato 2\u001b[0m\n",
      "├── \u001b[01;34mTomato 3\u001b[0m\n",
      "├── \u001b[01;34mTomato 4\u001b[0m\n",
      "├── \u001b[01;34mTomato Cherry Red\u001b[0m\n",
      "├── \u001b[01;34mTomato Heart\u001b[0m\n",
      "├── \u001b[01;34mTomato Maroon\u001b[0m\n",
      "├── \u001b[01;34mTomato not Ripened\u001b[0m\n",
      "├── \u001b[01;34mTomato Yellow\u001b[0m\n",
      "├── \u001b[01;34mWalnut\u001b[0m\n",
      "└── \u001b[01;34mWatermelon\u001b[0m\n",
      "\n",
      "131 directories, 0 files\n"
     ]
    }
   ],
   "source": [
    "!tree /home/louberehc/OCR/projets/8_cloud_computing/fruits_360/Training -L 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/home/louberehc/OCR/projets/8_cloud_computing/fruits_360/Test\u001b[0m\n",
      "├── \u001b[01;34mApple Braeburn\u001b[0m\n",
      "├── \u001b[01;34mApple Crimson Snow\u001b[0m\n",
      "├── \u001b[01;34mApple Golden 1\u001b[0m\n",
      "├── \u001b[01;34mApple Golden 2\u001b[0m\n",
      "├── \u001b[01;34mApple Golden 3\u001b[0m\n",
      "├── \u001b[01;34mApple Granny Smith\u001b[0m\n",
      "├── \u001b[01;34mApple Pink Lady\u001b[0m\n",
      "├── \u001b[01;34mApple Red 1\u001b[0m\n",
      "├── \u001b[01;34mApple Red 2\u001b[0m\n",
      "├── \u001b[01;34mApple Red 3\u001b[0m\n",
      "├── \u001b[01;34mApple Red Delicious\u001b[0m\n",
      "├── \u001b[01;34mApple Red Yellow 1\u001b[0m\n",
      "├── \u001b[01;34mApple Red Yellow 2\u001b[0m\n",
      "├── \u001b[01;34mApricot\u001b[0m\n",
      "├── \u001b[01;34mAvocado\u001b[0m\n",
      "├── \u001b[01;34mAvocado ripe\u001b[0m\n",
      "├── \u001b[01;34mBanana\u001b[0m\n",
      "├── \u001b[01;34mBanana Lady Finger\u001b[0m\n",
      "├── \u001b[01;34mBanana Red\u001b[0m\n",
      "├── \u001b[01;34mBeetroot\u001b[0m\n",
      "├── \u001b[01;34mBlueberry\u001b[0m\n",
      "├── \u001b[01;34mCactus fruit\u001b[0m\n",
      "├── \u001b[01;34mCantaloupe 1\u001b[0m\n",
      "├── \u001b[01;34mCantaloupe 2\u001b[0m\n",
      "├── \u001b[01;34mCarambula\u001b[0m\n",
      "├── \u001b[01;34mCauliflower\u001b[0m\n",
      "├── \u001b[01;34mCherry 1\u001b[0m\n",
      "├── \u001b[01;34mCherry 2\u001b[0m\n",
      "├── \u001b[01;34mCherry Rainier\u001b[0m\n",
      "├── \u001b[01;34mCherry Wax Black\u001b[0m\n",
      "├── \u001b[01;34mCherry Wax Red\u001b[0m\n",
      "├── \u001b[01;34mCherry Wax Yellow\u001b[0m\n",
      "├── \u001b[01;34mChestnut\u001b[0m\n",
      "├── \u001b[01;34mClementine\u001b[0m\n",
      "├── \u001b[01;34mCocos\u001b[0m\n",
      "├── \u001b[01;34mCorn\u001b[0m\n",
      "├── \u001b[01;34mCorn Husk\u001b[0m\n",
      "├── \u001b[01;34mCucumber Ripe\u001b[0m\n",
      "├── \u001b[01;34mCucumber Ripe 2\u001b[0m\n",
      "├── \u001b[01;34mDates\u001b[0m\n",
      "├── \u001b[01;34mEggplant\u001b[0m\n",
      "├── \u001b[01;34mFig\u001b[0m\n",
      "├── \u001b[01;34mGinger Root\u001b[0m\n",
      "├── \u001b[01;34mGranadilla\u001b[0m\n",
      "├── \u001b[01;34mGrape Blue\u001b[0m\n",
      "├── \u001b[01;34mGrapefruit Pink\u001b[0m\n",
      "├── \u001b[01;34mGrapefruit White\u001b[0m\n",
      "├── \u001b[01;34mGrape Pink\u001b[0m\n",
      "├── \u001b[01;34mGrape White\u001b[0m\n",
      "├── \u001b[01;34mGrape White 2\u001b[0m\n",
      "├── \u001b[01;34mGrape White 3\u001b[0m\n",
      "├── \u001b[01;34mGrape White 4\u001b[0m\n",
      "├── \u001b[01;34mGuava\u001b[0m\n",
      "├── \u001b[01;34mHazelnut\u001b[0m\n",
      "├── \u001b[01;34mHuckleberry\u001b[0m\n",
      "├── \u001b[01;34mKaki\u001b[0m\n",
      "├── \u001b[01;34mKiwi\u001b[0m\n",
      "├── \u001b[01;34mKohlrabi\u001b[0m\n",
      "├── \u001b[01;34mKumquats\u001b[0m\n",
      "├── \u001b[01;34mLemon\u001b[0m\n",
      "├── \u001b[01;34mLemon Meyer\u001b[0m\n",
      "├── \u001b[01;34mLimes\u001b[0m\n",
      "├── \u001b[01;34mLychee\u001b[0m\n",
      "├── \u001b[01;34mMandarine\u001b[0m\n",
      "├── \u001b[01;34mMango\u001b[0m\n",
      "├── \u001b[01;34mMango Red\u001b[0m\n",
      "├── \u001b[01;34mMangostan\u001b[0m\n",
      "├── \u001b[01;34mMaracuja\u001b[0m\n",
      "├── \u001b[01;34mMelon Piel de Sapo\u001b[0m\n",
      "├── \u001b[01;34mMulberry\u001b[0m\n",
      "├── \u001b[01;34mNectarine\u001b[0m\n",
      "├── \u001b[01;34mNectarine Flat\u001b[0m\n",
      "├── \u001b[01;34mNut Forest\u001b[0m\n",
      "├── \u001b[01;34mNut Pecan\u001b[0m\n",
      "├── \u001b[01;34mOnion Red\u001b[0m\n",
      "├── \u001b[01;34mOnion Red Peeled\u001b[0m\n",
      "├── \u001b[01;34mOnion White\u001b[0m\n",
      "├── \u001b[01;34mOrange\u001b[0m\n",
      "├── \u001b[01;34mPapaya\u001b[0m\n",
      "├── \u001b[01;34mPassion Fruit\u001b[0m\n",
      "├── \u001b[01;34mPeach\u001b[0m\n",
      "├── \u001b[01;34mPeach 2\u001b[0m\n",
      "├── \u001b[01;34mPeach Flat\u001b[0m\n",
      "├── \u001b[01;34mPear\u001b[0m\n",
      "├── \u001b[01;34mPear 2\u001b[0m\n",
      "├── \u001b[01;34mPear Abate\u001b[0m\n",
      "├── \u001b[01;34mPear Forelle\u001b[0m\n",
      "├── \u001b[01;34mPear Kaiser\u001b[0m\n",
      "├── \u001b[01;34mPear Monster\u001b[0m\n",
      "├── \u001b[01;34mPear Red\u001b[0m\n",
      "├── \u001b[01;34mPear Stone\u001b[0m\n",
      "├── \u001b[01;34mPear Williams\u001b[0m\n",
      "├── \u001b[01;34mPepino\u001b[0m\n",
      "├── \u001b[01;34mPepper Green\u001b[0m\n",
      "├── \u001b[01;34mPepper Orange\u001b[0m\n",
      "├── \u001b[01;34mPepper Red\u001b[0m\n",
      "├── \u001b[01;34mPepper Yellow\u001b[0m\n",
      "├── \u001b[01;34mPhysalis\u001b[0m\n",
      "├── \u001b[01;34mPhysalis with Husk\u001b[0m\n",
      "├── \u001b[01;34mPineapple\u001b[0m\n",
      "├── \u001b[01;34mPineapple Mini\u001b[0m\n",
      "├── \u001b[01;34mPitahaya Red\u001b[0m\n",
      "├── \u001b[01;34mPlum\u001b[0m\n",
      "├── \u001b[01;34mPlum 2\u001b[0m\n",
      "├── \u001b[01;34mPlum 3\u001b[0m\n",
      "├── \u001b[01;34mPomegranate\u001b[0m\n",
      "├── \u001b[01;34mPomelo Sweetie\u001b[0m\n",
      "├── \u001b[01;34mPotato Red\u001b[0m\n",
      "├── \u001b[01;34mPotato Red Washed\u001b[0m\n",
      "├── \u001b[01;34mPotato Sweet\u001b[0m\n",
      "├── \u001b[01;34mPotato White\u001b[0m\n",
      "├── \u001b[01;34mQuince\u001b[0m\n",
      "├── \u001b[01;34mRambutan\u001b[0m\n",
      "├── \u001b[01;34mRaspberry\u001b[0m\n",
      "├── \u001b[01;34mRedcurrant\u001b[0m\n",
      "├── \u001b[01;34mSalak\u001b[0m\n",
      "├── \u001b[01;34mStrawberry\u001b[0m\n",
      "├── \u001b[01;34mStrawberry Wedge\u001b[0m\n",
      "├── \u001b[01;34mTamarillo\u001b[0m\n",
      "├── \u001b[01;34mTangelo\u001b[0m\n",
      "├── \u001b[01;34mTomato 1\u001b[0m\n",
      "├── \u001b[01;34mTomato 2\u001b[0m\n",
      "├── \u001b[01;34mTomato 3\u001b[0m\n",
      "├── \u001b[01;34mTomato 4\u001b[0m\n",
      "├── \u001b[01;34mTomato Cherry Red\u001b[0m\n",
      "├── \u001b[01;34mTomato Heart\u001b[0m\n",
      "├── \u001b[01;34mTomato Maroon\u001b[0m\n",
      "├── \u001b[01;34mTomato not Ripened\u001b[0m\n",
      "├── \u001b[01;34mTomato Yellow\u001b[0m\n",
      "├── \u001b[01;34mWalnut\u001b[0m\n",
      "└── \u001b[01;34mWatermelon\u001b[0m\n",
      "\n",
      "131 directories, 0 files\n"
     ]
    }
   ],
   "source": [
    "!tree /home/louberehc/OCR/projets/8_cloud_computing/fruits_360/Test -L 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy some random images from the training dataset in the subset dir.\n",
    "# 10 images per fruits among the 5 first fruits appearing in listdir.\n",
    "n_images = 10\n",
    "n_fruit_types = 32\n",
    "\n",
    "for fruit_name in os.listdir(TRAIN_PATH)[:n_fruit_types]:\n",
    "    train_fruit_path = os.path.join(TRAIN_PATH, fruit_name)\n",
    "    subset_fruit_path = os.path.join(IMAGE_SUBSET_PATH, fruit_name)\n",
    "    \n",
    "    if not os.path.exists(subset_fruit_path):\n",
    "        os.mkdir(subset_fruit_path)\n",
    "    \n",
    "    random_relative_filenames = random.sample(\n",
    "        os.listdir(train_fruit_path),\n",
    "        k=n_images\n",
    "    )\n",
    "\n",
    "    for fn in random_relative_filenames:\n",
    "        shutil.copy(\n",
    "            os.path.join(train_fruit_path, fn),\n",
    "            os.path.join(subset_fruit_path, fn)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mimages_subset\u001b[0m\n",
      "├── \u001b[01;34mApple Golden 2\u001b[0m\n",
      "│   ├── \u001b[01;35m20_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m284_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m313_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m320_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_170_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_187_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_238_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_289_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_305_100.jpg\u001b[0m\n",
      "│   └── \u001b[01;35mr_318_100.jpg\u001b[0m\n",
      "├── \u001b[01;34mApple Pink Lady\u001b[0m\n",
      "│   ├── \u001b[01;35m121_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m58_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m9_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_162_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_167_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_188_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_195_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_298_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_301_100.jpg\u001b[0m\n",
      "│   └── \u001b[01;35mr_43_100.jpg\u001b[0m\n",
      "├── \u001b[01;34mApple Red 1\u001b[0m\n",
      "│   ├── \u001b[01;35m156_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m205_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m254_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m258_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m319_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_101_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_132_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_18_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_181_100.jpg\u001b[0m\n",
      "│   └── \u001b[01;35mr_223_100.jpg\u001b[0m\n",
      "├── \u001b[01;34mCherry 1\u001b[0m\n",
      "│   ├── \u001b[01;35m117_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m162_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m271_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m288_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m303_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m31_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_141_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_19_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_25_100.jpg\u001b[0m\n",
      "│   └── \u001b[01;35mr_298_100.jpg\u001b[0m\n",
      "├── \u001b[01;34mCherry Wax Red\u001b[0m\n",
      "│   ├── \u001b[01;35m187_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m304_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m308_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m37_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_13_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_144_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_181_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_21_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_244_100.jpg\u001b[0m\n",
      "│   └── \u001b[01;35mr_253_100.jpg\u001b[0m\n",
      "├── \u001b[01;34mCucumber Ripe\u001b[0m\n",
      "│   ├── \u001b[01;35m116_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m155_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m167_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m264_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m278_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m66_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_113_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_131_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_144_100.jpg\u001b[0m\n",
      "│   └── \u001b[01;35mr_146_100.jpg\u001b[0m\n",
      "├── \u001b[01;34mDates\u001b[0m\n",
      "│   ├── \u001b[01;35m256_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m294_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m40_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m69_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_174_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_196_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_201_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_230_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_288_100.jpg\u001b[0m\n",
      "│   └── \u001b[01;35mr_5_100.jpg\u001b[0m\n",
      "├── \u001b[01;34mGranadilla\u001b[0m\n",
      "│   ├── \u001b[01;35m135_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m256_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m269_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_214_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_219_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_256_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_267_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_304_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_87_100.jpg\u001b[0m\n",
      "│   └── \u001b[01;35mr_95_100.jpg\u001b[0m\n",
      "├── \u001b[01;34mGrapefruit White\u001b[0m\n",
      "│   ├── \u001b[01;35m1_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m131_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m132_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m184_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m210_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m224_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m296_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_187_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_234_100.jpg\u001b[0m\n",
      "│   └── \u001b[01;35mr_271_100.jpg\u001b[0m\n",
      "├── \u001b[01;34mGrape White 3\u001b[0m\n",
      "│   ├── \u001b[01;35m199_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m29_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m43_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m86_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_102_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_195_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_313_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_326_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_70_100.jpg\u001b[0m\n",
      "│   └── \u001b[01;35mr_83_100.jpg\u001b[0m\n",
      "├── \u001b[01;34mGrape White 4\u001b[0m\n",
      "│   ├── \u001b[01;35m108_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m110_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m169_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m17_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m262_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m312_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m92_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_115_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_164_100.jpg\u001b[0m\n",
      "│   └── \u001b[01;35mr_40_100.jpg\u001b[0m\n",
      "├── \u001b[01;34mGuava\u001b[0m\n",
      "│   ├── \u001b[01;35m15_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m158_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m177_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m234_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m327_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_113_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_201_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_220_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_235_100.jpg\u001b[0m\n",
      "│   └── \u001b[01;35mr_93_100.jpg\u001b[0m\n",
      "├── \u001b[01;34mHuckleberry\u001b[0m\n",
      "│   ├── \u001b[01;35m139_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m167_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m168_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m188_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m261_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m324_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m87_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_14_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_165_100.jpg\u001b[0m\n",
      "│   └── \u001b[01;35mr_321_100.jpg\u001b[0m\n",
      "├── \u001b[01;34mKiwi\u001b[0m\n",
      "│   ├── \u001b[01;35m137_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m146_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m23_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m25_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m263_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m279_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m291_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_222_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_268_100.jpg\u001b[0m\n",
      "│   └── \u001b[01;35mr_295_100.jpg\u001b[0m\n",
      "├── \u001b[01;34mKumquats\u001b[0m\n",
      "│   ├── \u001b[01;35m162_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m21_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m71_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_123_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_19_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_214_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_219_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_234_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_316_100.jpg\u001b[0m\n",
      "│   └── \u001b[01;35mr_65_100.jpg\u001b[0m\n",
      "├── \u001b[01;34mLemon Meyer\u001b[0m\n",
      "│   ├── \u001b[01;35m221_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m226_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m238_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m255_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m323_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m69_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m83_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_255_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_266_100.jpg\u001b[0m\n",
      "│   └── \u001b[01;35mr_272_100.jpg\u001b[0m\n",
      "├── \u001b[01;34mMaracuja\u001b[0m\n",
      "│   ├── \u001b[01;35m192_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m235_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m248_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m60_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_126_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_137_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_225_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_255_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_309_100.jpg\u001b[0m\n",
      "│   └── \u001b[01;35mr_5_100.jpg\u001b[0m\n",
      "├── \u001b[01;34mNut Forest\u001b[0m\n",
      "│   ├── \u001b[01;35m229_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m245_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m415_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m67_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m86_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_193_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr2_169_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr2_35_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr2_69_100.jpg\u001b[0m\n",
      "│   └── \u001b[01;35mr2_71_100.jpg\u001b[0m\n",
      "├── \u001b[01;34mOnion White\u001b[0m\n",
      "│   ├── \u001b[01;35m11_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m139_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m75_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_130_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_142_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_156_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_162_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr2_116_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr2_145_100.jpg\u001b[0m\n",
      "│   └── \u001b[01;35mr_63_100.jpg\u001b[0m\n",
      "├── \u001b[01;34mPeach\u001b[0m\n",
      "│   ├── \u001b[01;35m119_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m142_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m15_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m162_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m211_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m265_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m287_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_1_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_135_100.jpg\u001b[0m\n",
      "│   └── \u001b[01;35mr_234_100.jpg\u001b[0m\n",
      "├── \u001b[01;34mPear Kaiser\u001b[0m\n",
      "│   ├── \u001b[01;35m100_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m117_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m118_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m182_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m191_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m77_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m94_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_152_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_175_100.jpg\u001b[0m\n",
      "│   └── \u001b[01;35mr_183_100.jpg\u001b[0m\n",
      "├── \u001b[01;34mPear Red\u001b[0m\n",
      "│   ├── \u001b[01;35m12_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m151_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m154_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m29_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_15_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_167_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr2_234_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_224_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_260_100.jpg\u001b[0m\n",
      "│   └── \u001b[01;35mr_38_100.jpg\u001b[0m\n",
      "├── \u001b[01;34mPepper Red\u001b[0m\n",
      "│   ├── \u001b[01;35m114_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m274_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_117_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr2_142_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr2_186_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr2_277_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr2_94_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_55_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_69_100.jpg\u001b[0m\n",
      "│   └── \u001b[01;35mr_80_100.jpg\u001b[0m\n",
      "├── \u001b[01;34mPitahaya Red\u001b[0m\n",
      "│   ├── \u001b[01;35m100_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m166_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m292_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m65_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_19_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_223_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_266_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_31_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_56_100.jpg\u001b[0m\n",
      "│   └── \u001b[01;35mr_74_100.jpg\u001b[0m\n",
      "├── \u001b[01;34mPomelo Sweetie\u001b[0m\n",
      "│   ├── \u001b[01;35m107_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m113_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m42_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m60_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_116_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr2_16_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr2_187_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr2_98_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_71_100.jpg\u001b[0m\n",
      "│   └── \u001b[01;35mr_78_100.jpg\u001b[0m\n",
      "├── \u001b[01;34mPotato White\u001b[0m\n",
      "│   ├── \u001b[01;35m139_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m181_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m21_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m37_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m49_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_0_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_192_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_195_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr2_166_100.jpg\u001b[0m\n",
      "│   └── \u001b[01;35mr_55_100.jpg\u001b[0m\n",
      "├── \u001b[01;34mRambutan\u001b[0m\n",
      "│   ├── \u001b[01;35m126_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m209_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m309_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m327_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_140_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_229_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_258_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_30_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_319_100.jpg\u001b[0m\n",
      "│   └── \u001b[01;35mr_325_100.jpg\u001b[0m\n",
      "├── \u001b[01;34mRaspberry\u001b[0m\n",
      "│   ├── \u001b[01;35m137_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m149_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m170_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m182_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m278_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m62_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m71_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_135_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_150_100.jpg\u001b[0m\n",
      "│   └── \u001b[01;35mr_292_100.jpg\u001b[0m\n",
      "├── \u001b[01;34mStrawberry Wedge\u001b[0m\n",
      "│   ├── \u001b[01;35m190_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m207_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m227_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m238_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_132_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_2_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_221_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_244_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr2_85_100.jpg\u001b[0m\n",
      "│   └── \u001b[01;35mr2_96_100.jpg\u001b[0m\n",
      "├── \u001b[01;34mTamarillo\u001b[0m\n",
      "│   ├── \u001b[01;35m188_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m61_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m7_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m77_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_217_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_231_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_304_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_317_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_33_100.jpg\u001b[0m\n",
      "│   └── \u001b[01;35mr_79_100.jpg\u001b[0m\n",
      "├── \u001b[01;34mTomato 2\u001b[0m\n",
      "│   ├── \u001b[01;35m123_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m208_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35m85_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_138_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr_141_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr2_119_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr2_133_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr2_151_100.jpg\u001b[0m\n",
      "│   ├── \u001b[01;35mr2_190_100.jpg\u001b[0m\n",
      "│   └── \u001b[01;35mr_300_100.jpg\u001b[0m\n",
      "└── \u001b[01;34mTomato not Ripened\u001b[0m\n",
      "    ├── \u001b[01;35m102_100.jpg\u001b[0m\n",
      "    ├── \u001b[01;35m11_100.jpg\u001b[0m\n",
      "    ├── \u001b[01;35m13_100.jpg\u001b[0m\n",
      "    ├── \u001b[01;35m22_100.jpg\u001b[0m\n",
      "    ├── \u001b[01;35m292_100.jpg\u001b[0m\n",
      "    ├── \u001b[01;35m310_100.jpg\u001b[0m\n",
      "    ├── \u001b[01;35mr_165_100.jpg\u001b[0m\n",
      "    ├── \u001b[01;35mr_169_100.jpg\u001b[0m\n",
      "    ├── \u001b[01;35mr_213_100.jpg\u001b[0m\n",
      "    └── \u001b[01;35mr_92_100.jpg\u001b[0m\n",
      "\n",
      "32 directories, 320 files\n"
     ]
    }
   ],
   "source": [
    "!tree images_subset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.  [&#9650;](#toc0_) <a id='toc2_'></a>Launch a Spark Session"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "First, I had errors of modules not found when using PandasUDF.\n",
    "\n",
    "To avoid that, I had to create a conda environment (p8_env) with packages called in such functions (tensorflow, numpy...) , conda-pack it, and provide\n",
    "it to the spark session. Click [here](https://spark.apache.org/docs/latest/api/python/user_guide/python_packaging.html) to see the ad-hoc documentation.\n",
    "\n",
    "This makes the session much longer to open because the dependencies are installed on the driver and the executors, but then, it works.\n",
    "\n",
    "It introduces some new problems with the heartbeater, but I neglect it for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/17 20:01:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/07/17 20:02:16 ERROR Inbox: Ignoring error\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:600)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "23/07/17 20:02:16 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:600)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "23/07/17 20:02:26 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:34229\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/07/17 20:02:26 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:641)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1111)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:244)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2088)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:117)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:116)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:611)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:610)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:648)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@localhost:34229\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n"
     ]
    }
   ],
   "source": [
    "os.environ['PYSPARK_PYTHON'] = \"/home/louberehc/miniconda3/envs/p8_env/bin/python\" \n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = \"/home/louberehc/miniconda3/envs/p8_env/bin/python\" \n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName('P8')\n",
    "    .master('local[*]')\n",
    "    .config(\"spark.sql.parquet.writeLegacyFormat\", 'true')\n",
    "    .config(\n",
    "        \"spark.archives\",  # 'spark.yarn.dist.archives' in YARN.\n",
    "        \"p8_env.tar.gz#environment\"\n",
    "    )\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://localhost:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>P8</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fc595cbe020>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.  [&#9650;](#toc0_) <a id='toc3_'></a>Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = spark.read.format(\"binaryFile\") \\\n",
    "    .option(\"pathGlobFilter\", \"*.jpg\") \\\n",
    "    .option(\"recursiveFileLookup\", \"true\") \\\n",
    "    .load(IMAGE_SUBSET_PATH)\n",
    "    \n",
    "# Add a label column from the image path\n",
    "images = images.withColumn('label', element_at(split(images['path'], '/'),-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- path: string (nullable = true)\n",
      " |-- modificationTime: timestamp (nullable = true)\n",
      " |-- length: long (nullable = true)\n",
      " |-- content: binary (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "images.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------+---------+\n",
      "|path                                                                                  |label    |\n",
      "+--------------------------------------------------------------------------------------+---------+\n",
      "|file:/home/louberehc/OCR/projets/8_cloud_computing/images_subset/Raspberry/136_100.jpg|Raspberry|\n",
      "|file:/home/louberehc/OCR/projets/8_cloud_computing/images_subset/Raspberry/11_100.jpg |Raspberry|\n",
      "|file:/home/louberehc/OCR/projets/8_cloud_computing/images_subset/Raspberry/39_100.jpg |Raspberry|\n",
      "|file:/home/louberehc/OCR/projets/8_cloud_computing/images_subset/Raspberry/325_100.jpg|Raspberry|\n",
      "|file:/home/louberehc/OCR/projets/8_cloud_computing/images_subset/Raspberry/116_100.jpg|Raspberry|\n",
      "|file:/home/louberehc/OCR/projets/8_cloud_computing/images_subset/Pineapple/112_100.jpg|Pineapple|\n",
      "|file:/home/louberehc/OCR/projets/8_cloud_computing/images_subset/Pineapple/160_100.jpg|Pineapple|\n",
      "|file:/home/louberehc/OCR/projets/8_cloud_computing/images_subset/Pineapple/49_100.jpg |Pineapple|\n",
      "|file:/home/louberehc/OCR/projets/8_cloud_computing/images_subset/Pineapple/154_100.jpg|Pineapple|\n",
      "|file:/home/louberehc/OCR/projets/8_cloud_computing/images_subset/Pineapple/35_100.jpg |Pineapple|\n",
      "+--------------------------------------------------------------------------------------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Inspect path and label\n",
    "print(images.select('path','label').show(10,False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|content                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[FF D8 FF E0 00 10 4A 46 49 46 00 01 01 00 00 01 00 01 00 00 FF DB 00 43 00 02 01 01 01 01 01 02 01 01 01 02 02 02 02 02 04 03 02 02 02 02 05 04 04 03 04 06 05 06 06 06 05 06 06 06 07 09 08 06 07 09 07 06 06 08 0B 08 09 0A 0A 0A 0A 0A 06 08 0B 0C 0B 0A 0C 09 0A 0A 0A FF DB 00 43 01 02 02 02 02 02 02 05 03 03 05 0A 07 06 07 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A 0A FF C0 00 11 08 00 64 00 64 03 01 22 00 02 11 01 03 11 01 FF C4 00 1F 00 00 01 05 01 01 01 01 01 01 00 00 00 00 00 00 00 00 01 02 03 04 05 06 07 08 09 0A 0B FF C4 00 B5 10 00 02 01 03 03 02 04 03 05 05 04 04 00 00 01 7D 01 02 03 00 04 11 05 12 21 31 41 06 13 51 61 07 22 71 14 32 81 91 A1 08 23 42 B1 C1 15 52 D1 F0 24 33 62 72 82 09 0A 16 17 18 19 1A 25 26 27 28 29 2A 34 35 36 37 38 39 3A 43 44 45 46 47 48 49 4A 53 54 55 56 57 58 59 5A 63 64 65 66 67 68 69 6A 73 74 75 76 77 78 79 7A 83 84 85 86 87 88 89 8A 92 93 94 95 96 97 98 99 9A A2 A3 A4 A5 A6 A7 A8 A9 AA B2 B3 B4 B5 B6 B7 B8 B9 BA C2 C3 C4 C5 C6 C7 C8 C9 CA D2 D3 D4 D5 D6 D7 D8 D9 DA E1 E2 E3 E4 E5 E6 E7 E8 E9 EA F1 F2 F3 F4 F5 F6 F7 F8 F9 FA FF C4 00 1F 01 00 03 01 01 01 01 01 01 01 01 01 00 00 00 00 00 00 01 02 03 04 05 06 07 08 09 0A 0B FF C4 00 B5 11 00 02 01 02 04 04 03 04 07 05 04 04 00 01 02 77 00 01 02 03 11 04 05 21 31 06 12 41 51 07 61 71 13 22 32 81 08 14 42 91 A1 B1 C1 09 23 33 52 F0 15 62 72 D1 0A 16 24 34 E1 25 F1 17 18 19 1A 26 27 28 29 2A 35 36 37 38 39 3A 43 44 45 46 47 48 49 4A 53 54 55 56 57 58 59 5A 63 64 65 66 67 68 69 6A 73 74 75 76 77 78 79 7A 82 83 84 85 86 87 88 89 8A 92 93 94 95 96 97 98 99 9A A2 A3 A4 A5 A6 A7 A8 A9 AA B2 B3 B4 B5 B6 B7 B8 B9 BA C2 C3 C4 C5 C6 C7 C8 C9 CA D2 D3 D4 D5 D6 D7 D8 D9 DA E2 E3 E4 E5 E6 E7 E8 E9 EA F2 F3 F4 F5 F6 F7 F8 F9 FA FF DA 00 0C 03 01 00 02 11 03 11 00 3F 00 FD E4 F1 FF 00 8F 3C 2F F0 C7 C1 DA 87 8E FC 67 A9 A5 9E 9B A6 DB 34 D7 53 B9 E8 A0 67 8F 53 ED 5F 9D 7F 1B FF 00 E0 B0 5F 18 97 5C 9A 4F 86 76 36 FA 6D 9D C3 91 A5 E9 ED 67 1C D7 0F 1F 45 79 0B 83 82 7A F1 5E F5 FF 00 05 79 D7 75 6B 4F 80 9A 5F 86 AC 2F 36 DB EA BA B9 5B E8 03 01 E6 A4 6B BC 0F 70 08 AF C9 5F 88 FF 00 1C FC 39 E0 BF 19 E9 DF 13 66 B4 96 4D 32 F6 C9 25 B3 20 FF 00 AD 56 8C 32 90 3D B3 F9 D7 DA 64 39 65 29 E1 E1 55 C1 4E 53 6F 75 7B 24 DA DB 6B BB 37 D5 ED 63 AB 29 CA B1 19 CE 60 E9 C6 32 92 8D ED 18 BB 73 4B 96 F6 6F CE F6 4B C9 BF 4F 41 BF FF 00 82 9E 7E DA 3E 21 F1 C5 CF 83 F4 FF 00 8C 5E 22 D3 96 C4 31 D5 2E A3 D5 67 6F 27 D9 57 77 5A F4 CF 0F 7F C1 59 3F 68 1D 33 E0 C5 FF 00 87 2D FE 31 5E 4E 65 81 95 7C 4B A9 B2 BD D4 6D CA 9D 8E DC E7 8C F1 C8 ED 5F 14 7C 39 F8 9F A1 78 CE E3 5E 86 F9 67 B5 D6 3C 45 3C B3 89 E0 52 FC 33 13 B0 01 DC 0E 2B 9E F8 B9 E2 EF 0C F8 77 4D B7 F0 87 81 F5 66 B9 00 6E B8 56 24 88 9C 92 48 E7 BE 6B EA E5 96 2A D8 AF AB FB 34 9F BB BC 53 5B 5D CA F6 B2 D7 48 FA 6C CF D3 AA 70 1E 07 1D 89 A7 81 F6 0E 94 A3 CB B7 36 BE EA 73 6E 57 7A 5E F1 49 BB 3B 3E A7 D2 3A B7 FC 15 7B F6 B1 F8 75 6F 6D E2 4B 0F DA 87 5D D7 94 CF 83 6B 3E A3 23 0C 83 9C 10 4E 08 C6 2B EE 8F 80 DF F0 5F AF 84 3E 24 F8 61 A3 6B 1F 17 3C 01 AB 59 EA 6D 69 B3 55 BE B6 0A 2D DA 64 3B 59 94 76 07 19 F4 04 90 3A 57 E4 27 C2 5F 03 E9 3A AE 87 77 E2 5D 4B 48 4B B6 B6 50 67 33 41 E6 24 40 F3 D0 F0 0E 39 AE 96 F7 C5 3E 11 1E 18 B9 D3 2C 75 78 5A 61 0B 41 14 26 32 B1 6D 24 95 DA 8B 80 A7 07 A8 FC 6A 73 0C AB 2D AD FE CE E9 73 CA 2F E2 4A D6 FF 00 C0 52 FC 48 CE B8 57 87 94 9E 13 09 09 AA B0 95 A5 38 A5 6B 3E 8E 3E F2 BA DD 4A CB E6 8F D6 1D 5B FE 0B 8F A6 6A D7 2D 1F 80 3E 17 5B AC 0D 23 0B 6B DD 62 E9 BC A9 80 38 E1 A3 3D 7D 6A F6 9D FF 00 05 C8 F8 7F A2 F8 6A FD 3E 26 7C 3F 1A 7E BB 6C 03 5A C3 6D 7C AD 6F 73 19 1C 3A 92 77 11 D4 71 FD 2B F1 F7 C2 1E 2B D4 34 2F 00 B6 8D 73 F1 06 49 AC 15 5C 45 66 74 F9 13 CE E4 92 15 9B 83 83 9A C3 F0 B7 8D 3C 75 E3 DB 7B 2D 0B C2 D7 96 B7 06 DA 76 59 74 EB B8 16 42 23 0D 91 8C 8C 84 E7 1C 74 AE 55 C3 78 09 73 27 4E 3C B1 7B BE 68 B6 BD 5B F2 D5 5A DE 67 CE 52 F0 F2 A3 95 49 FD 6E 5E CE 2D A7 26 D2 B2 D7 AB 85 93 D3 B5 96 9A 9F AE 1A 6F FC 17 8A F7 5F B9 7B 5D 13 E1 FF 00 87 BC E1 CC 56 B7 37 73 24 8E 3D 39 38 C9 15 EF FF 00 B2 E7 FC 15 7B F6 7C FD A1 FC 40 3C 05 E2 26 6F 07 F8 8C 42 0A 58 6B 57 28 A9 72 E3 01 C4 4F D1 B0 58 60 75 E4 57 E2 7F 89 F4 4D 47 E2 6D DD C5 E5 EE 8F 6F A2 6A 9A 6D A9 02 6D 29 80 89 84 6B D0 A1 F9 B2 71 D4 7A 56 27 C0 D9 F4 CF 89 F3 DE F8 87 C7 32 DD 35 C7 86 90 3C 6C B2 3C 62 48 CF A9 5C 1C E4 0E BC 56 55 B2 1C A3 11 86 94 F9 14 54 56 BC 9F 12 6F E1 6B 56 A4 9B D3 54 BA 9C F5 38 4B 0F 0C B6 A6 36 8E 2A 56 A6 97 32 76 A9 66 EF CB F0 A8 DD 49 E9 75 66 AF B5 8F E9 B9 24 49 50 49 1B 86 53 D1 94 E4 1A 5A FC AD FF 00 82 68 FF 00 C1 41 F5 CF 05 78 8B 4A F0 06 B9 E3 1B 8D 4B C1 5A 95 C8 B7 8A D2 FE 53 2C 9A 43 B9 01 7C A3 D7 CB 2E 4E 57 D5 B3 5F AA 2A CA CA 19 58 10 46 41 07 AD 7C 26 67 96 54 CB 6A A4 DD E2 F6 76 B6 DB A6 BA 35 D7 A6 CD 68 CF 8A C3 62 65 5A 53 A7 52 0E 13 83 B3 4F F0 6B C9 FD FA 34 C5 A2 8A 2B CC 3A CF CE AF F8 2C 05 9E BB E2 0F 8D 3E 1D B1 D6 A5 9E 0D 1E CB 47 91 AD 16 37 28 27 67 04 31 C8 3D 98 91 5F 9C 7E 3E FD 9E 6C FC 41 63 65 A6 5F 4E 6C B4 BD 2E 06 16 96 30 B6 EF DE 39 2D B7 71 E4 AA 83 8C FA 8A FA CB F6 EB F8 F7 AB 7C 60 F8 AF E2 6F 13 8D 6E 7B CB 2D 33 54 92 DB 40 85 D8 AA 2D B2 E4 28 45 E8 32 3E 63 EA 72 4F 35 E0 9E 26 F1 B6 87 AA E8 10 45 6F 6C D1 EE F3 55 09 63 9D CA C4 1C E2 BF 43 C3 CB 1B 80 8D 38 42 56 E5 8C 76 5D 6C FA 3E D7 7A F7 BF 91 EF F0 96 2F 34 C1 53 8D 6C 2C 9D A5 26 D3 D1 DA F7 69 FF 00 E0 32 D1 EB 68 E8 78 D1 F8 37 AD FC 34 F1 2E 9D 36 8B 77 25 94 D2 42 F3 69 F2 34 78 91 CE 39 4F 53 9F 7A BD 1F EC 69 E2 AD 1B 44 7D 7B 5A 85 51 D6 23 3B 49 BC B3 EE C6 EE 7B E7 EB 47 ED 27 F1 FB C2 B3 EB 7A 01 F0 D3 4B 26 A5 A3 C6 A4 5D C1 26 DE 3B C6 FD CF 1C FD 4D 4B F1 53 F6 D1 F1 A7 C4 4F 86 A6 0F 0D F8 79 ED ED E4 8D A0 D5 E5 42 73 0B 63 8C 11 D0 11 8A FB 1C 33 C6 56 A1 ED 1C A4 A5 25 64 F9 56 AE EF E2 6D DD 26 B5 5D DE 96 D8 FD 42 73 E3 8C 65 1C 35 6A 10 51 75 5B 8C E5 2F 75 A4 A4 F9 75 6E ED 35 76 BC F4 B6 BA F9 8F 83 BE 3A EA 7F 0E A6 D7 34 F5 B0 4B AB 3D 62 D9 E0 BB 89 BA 97 19 0A FE C7 F9 D7 9B 7F 68 5F 19 19 FE 61 BB EF 2A 8C 64 9F 6A D1 D1 74 6D 6F C4 37 C5 F4 7B 2F 31 A2 71 24 AE 63 CA AF 3D FB 57 A7 F8 1F C3 1F 0F 7C 26 9A B5 DF C5 F8 19 6F 2E D7 CF D1 AE 21 38 85 95 BE 6C 8C 71 91 9C 63 B6 31 DA BD B7 88 C3 60 F9 A4 A3 76 D2 DB 56 ED D9 7E 37 FC 0F B2 C7 4F 2A C8 67 52 B4 21 CD 56 4A 3C CA 3A C9 B5 A2 76 F2 4E ED EF 6E 9A 1C 43 78 BB C6 7A A7 82 74 BF 02 5D 68 E2 3B 6B 69 C8 86 EB 90 EC CF 21 6E 4F FC 0A BD 03 52 F0 0E B7 FB 3F 6A 16 57 37 96 76 BE 74 D0 A4 BB DA 20 5B 9E 7E F7 D7 35 E7 5A 2C 3A BF 8E BC 4B 25 86 99 14 D2 59 24 A6 49 C4 4D 8C 46 0F 5C F6 E2 BA EF 1A 4B A9 78 B6 6B 6D 26 7F 1C DC DC 59 E9 F1 08 2D 13 50 1E 63 A6 33 85 0C 30 48 19 C7 3D 2B 93 15 4E 2A A4 68 E8 A2 EF 29 2B 3D 6F DE DD 5B E9 A2 3E 5B 1D 46 AC 65 0A 10 94 61 09 B9 4E A4 55 EE F9 B6 F4 D6 FA 33 7B E2 5F C7 2D 47 C6 92 58 6A DA 6E A9 77 6F 2D A2 15 65 37 4D B4 B0 EB 80 4E 3F 1F 4C 54 36 1A D7 8D E2 F8 6B A7 7C 42 5D 7A 47 3A 9D ED C5 94 B2 C0 FB 64 0A 1C FF 00 10 E5 B2 0E 30 78 C2 81 DA B9 4F 86 1F 0F 6F 3C 51 E2 98 74 6D 7B 51 8E DF 4F FB 6C AB 79 29 9C 0F 30 A8 5E 31 FD DE D9 F5 CD 6A 78 A2 76 B5 B3 BD F0 77 87 A5 81 45 9E A4 CB 67 63 17 DC 8D 7F BD 8E 99 38 EB F4 AE 39 61 30 34 1C 70 B4 62 9D 9A 6D F6 4D BE BE AF E4 8F 94 CE B0 B9 7E 5D 28 60 70 DF 12 6A 4D DA EB 95 DF 46 FD 5A EF 64 86 7C 3F F8 8F A8 FC 20 F1 6B B1 59 EE 2D 6F 2D 9A 35 CB 1C 99 37 1C 10 07 43 C8 1F 85 7E CD 7F C1 24 3F E0 A2 B6 BF 16 34 BB 3F 80 1F 14 FC 54 5B 57 B7 B1 48 F4 09 6F 65 5D D2 2A 2F CD 6E 58 FC CD 20 07 8C 93 F2 AE 07 4A FC 64 D3 F4 B1 6B E1 8B 4F 19 DE B4 CF 2E 9F E2 19 62 48 19 89 43 2A 43 6F 22 9D BD 0F FA D6 FC AB A1 F8 79 F1 6B C4 FE 10 F8 B7 17 8E 6D 6F 9A DE F6 7D 42 3B 9B 69 21 6D 9B 5D 48 24 8C 7D DE 98 E2 B9 F3 6C B7 0D 9A D1 95 36 AE ED AB 5F CC AD 66 93 EA 93 BB B6 EB 4E D6 FC FB 89 A8 47 17 51 62 B0 B6 58 8A 4B DE E8 A6 95 9F 23 5E 69 DE FD 25 6B 75 3F A7 3A 2B CC FF 00 63 EF DA 0F C2 FF 00 B4 F7 EC F1 E1 CF 8B BE 16 BE F3 96 F2 D3 C8 BE 56 93 73 C5 75 17 C9 2A B1 F5 C8 DD F4 60 7B D1 5F 8A E2 28 54 C3 57 95 1A 8A D2 8B 69 FC BF AF C4 F3 A8 D5 85 7A 31 A9 1D 9A BF F5 F9 7A A3 F1 87 E2 87 C2 DF 88 36 9F 11 35 6B D9 75 86 B7 48 2E 52 CE 1D 32 72 4C 2B 39 C2 48 EE BF 98 AF 2F F1 5F 87 BC 7B A7 78 AA 44 F1 46 92 F7 DA 3C 31 04 9E CA C1 CE EB 68 82 E0 10 D9 CB 1C 72 49 3C 9C D7 D7 BF B6 9C A3 C4 5F B5 87 8B B4 5B 06 36 6B A7 F8 D1 AE 25 02 5E 67 0B 3E 5C 10 7B 13 9F CE BE 75 F1 9F C6 EF 0D FC 2F F1 CD EE A1 AE 58 AB C3 73 62 62 1B 7E 6C 32 71 83 9E 80 E2 BF 50 E7 A9 57 15 74 93 72 E9 CB AA BA 52 76 B7 6E 6D 1A BB FC 51 F5 3C 2D 99 E6 31 C3 D2 C3 D3 A4 AA 38 C2 C9 28 A5 2B 46 D1 4D 35 B4 9A 4E 57 D5 F9 F4 3C 7F E1 57 EC CB E1 7F 1D 5D 5C F8 87 C4 3A DD C0 B6 9A 76 FB 0C 24 6C 76 4C 9C 17 F4 38 C7 4C 54 9F 1E BF 66 4D 5B E0 CF 85 E6 D6 3C 1F E2 C9 FF 00 B2 EE D3 66 A1 6D E7 11 BF 9E 01 03 AF 14 DF 04 7E D3 89 A7 45 FD A5 AC E8 92 DA 8D EE AE 6C D0 79 65 03 12 A5 01 1C 1C 60 13 DF 19 EB 5C 97 C7 4F 8F 5E 21 F8 CF A9 43 A2 E9 32 5D 2E 9D 1E D5 8E DD 88 F9 DB A6 E6 C0 19 26 BD AC 2C 73 DA B9 85 AA AB 53 BA DE DC AA D6 EC B5 7E 7D FB 1F AE 50 87 1A E2 33 C8 7B 49 25 87 56 E6 52 E5 71 49 5A DB 7D AD 9D FB EB A5 8E B7 E0 2F C5 AF 84 1E 11 F8 23 7F A2 EB 5A 5C 11 EB 0F 70 E5 DC A8 2D 2E 7E E9 04 FB 60 7E 15 E3 D7 1F 11 75 DB 5B DB BD 3A DE F0 5D 69 B7 77 2E C6 CA EA 14 9D 17 71 39 64 59 01 08 C7 3F 79 70 7D EB 77 5C FD 9D 7C 7B A0 0B 39 2E 62 8A 47 BB 56 27 63 10 10 8E A8 4F AF 15 D5 7C 01 F0 3F C2 3D 53 C5 A5 3C 41 6F 72 AA 2C 65 90 41 71 26 4C 77 28 00 31 71 8C F4 DC 3B E1 B0 49 C5 7A 94 E3 97 52 75 31 11 7E D3 99 DD AB A6 95 AF B3 D2 DA EC F4 ED EB 78 8F EC 0C 03 C6 66 94 EA 4A BF 3B E6 69 7B D6 69 E9 6D 6E B5 D9 F9 18 1F 0B 3E 23 E8 3F 0B 7E 1C 6B BA 15 A6 9B 22 EB 7A C4 89 1A DD DC 02 55 6D C0 E5 71 D8 E4 93 9F 7A E3 6E 2F 61 D4 AE 20 B0 B6 7C EF 93 6B 95 3F 78 B3 71 D7 EB 8A DA F8 C1 0F 87 AC 3C 66 FF 00 65 8C CD 6F 22 86 01 5C A9 43 DF 83 D0 F5 A7 78 F7 E0 FE B9 E1 3B 5B 3F 19 5B DB BD B6 97 A8 43 15 CE 9B 23 92 5D C1 45 6D C4 F6 F9 89 1F 85 76 D2 96 1A 0A 35 2D 69 54 5A 5F AD 96 8B E5 72 B0 F5 72 98 CB EB D3 6E 13 AF AF BD AE AA 29 28 AF 45 D2 DD D9 D3 FC 57 D1 FF 00 E1 56 78 A2 C3 C3 16 D7 C8 EC BA 6C 32 49 98 D4 06 91 A3 05 87 1D B2 4D 79 D1 1E 22 BB F1 BB E8 DE 1A D3 E4 B8 BA D5 02 2D B4 6A 0E 57 77 D3 A7 7F C2 A9 EB DE 27 D4 AF F5 61 AA 78 8F 50 92 EA 70 41 67 95 CB 33 0E 83 9F F3 DA BA AF 0A E9 B7 5F 0E 7C 4F A7 78 CF C6 29 77 6F 75 7F 00 B9 B4 B5 8A 73 14 91 C3 92 11 BE 5F BA 4E 37 0F 66 1E B5 74 E8 BC 25 04 E5 69 4D A7 A7 77 BD BB D8 F9 8C 7D 35 94 60 13 AD 35 3A B2 4D 2E D2 7A BD B7 B2 EB E4 68 6B 51 EA 7A 45 8F FC 20 B0 6A 0C 24 D2 27 33 5C C3 13 7C B2 CF B5 55 F3 EE 02 63 FE 03 54 B5 2D 4C EA 9A 7C 50 68 82 35 BB 08 45 BF CD CA 33 11 F3 7D 78 C7 E3 54 AF FC 61 0D CE B9 AB 6B 46 39 D5 26 BA F3 24 69 67 05 F9 19 E7 00 03 9E B5 8F 67 A0 F8 82 C2 2B 4F 16 89 CB DB 6A 32 10 B8 1F EA D7 79 F9 47 A7 62 71 EA 2A 28 E1 79 62 A5 3B 29 37 7D 74 BC 9A BB 5F 87 E0 7E 6D 5D 4E 84 DC AA 49 29 AF 79 76 94 9E AD 7A 7A F4 D0 FD 8F FF 00 82 23 6A 7F B5 17 85 FF 00 63 6B AD 17 C1 7A 5D DC B6 91 78 CE F3 7B 4D 64 B2 7E F0 C1 6C 5B 05 81 38 E9 ED CD 15 F4 6F FC 11 13 C4 70 78 8F F6 0C D1 DC 5A 18 AE 2C F5 8B 9B 6B DD D1 85 67 90 24 4C 18 E3 A9 D8 C9 CF B0 A2 BF 26 CE B3 CA 74 73 6A D4 E7 84 A5 26 A4 EE DA 6D BD B5 DC FC EA 86 53 8A CC E9 7D 6D 63 2A D3 E7 72 7C B1 6B 96 37 94 B4 57 57 B5 D3 3E 5F FF 00 82 8C FC 05 F1 37 81 FF 00 69 3F 16 F8 F2 F2 DD E0 B6 D7 EC 66 9F 4B BB 52 70 CC F2 17 66 52 39 0C 32 47 1E 95 F0 57 C6 4F 0D C1 F1 CB C4 71 6B BE 17 D2 2E A0 D3 AE 24 0F 73 34 AA 37 49 B5 06 FF 00 2C 11 EC 46 3B 9E 6B F5 67 FE 0B 41 AC 78 AF 43 8B 41 BE B4 45 97 4E 8A CA 49 4C 72 45 F2 6E 0C 77 A9 23 B9 4C D7 C0 FA A7 86 34 89 3C 33 A7 5D F8 73 C4 2B 69 67 6B 1A 5C 58 DD ED C8 11 6D 0C 4F 51 9C 8A F6 70 D9 8C D6 1B 0F 5A 31 4A A7 22 D7 A7 55 77 E7 68 AB AE 9F 71 FA 1F 0A E6 B5 72 9A 92 AD F6 A3 27 08 B7 AA 4B 57 AD 96 AF DE 4D 79 6B AB 56 30 34 1F 0E FC 2D D0 74 BB 3F 0A 5D E8 BA 7D C4 70 DC 88 AE 20 BB 50 CC 10 9C 1E 4D 78 5F C7 F9 7C 03 F0 CF E3 D4 EF F0 CE 08 2E 2C 13 63 4D 62 77 79 2B 28 03 72 E5 4E 71 9F 43 57 3F 68 BF 1E 5F C1 A9 B3 E9 FA 84 4C 35 6B 08 66 97 CA 41 C3 90 0B 05 23 90 41 C8 FC 2A 6F D9 17 E1 AF 86 35 7D 7E EB C6 7F 12 C0 96 38 47 FA 3C 37 7C 86 63 D5 9B 3D 7D AB DB CB 63 53 01 97 CF 19 89 9B 94 65 D3 5B B6 FA 6F 6D FC AF D6 EB AF EB 59 2D 19 E4 B8 2A 99 D6 3E B4 E5 4E 51 6B D9 DD BE 79 49 F6 BE E9 A6 93 D1 AD FC 8E 77 E2 6F ED 59 E3 5F 1E EB 16 57 EF 65 15 A9 B2 8C A8 82 0D C6 37 F4 24 13 C9 AE 0B 49 F8 85 AC D9 3D F4 D6 C6 51 73 75 20 B8 86 78 0E D6 82 60 C4 E4 71 F7 4E 70 47 70 07 35 EF 7F 18 7E 00 FC 3E F0 1E B5 69 E3 FF 00 0C 5D 46 9A 60 99 DE E6 2B 89 01 4C E7 85 51 D4 83 F5 A8 7F E1 1E F8 3F F0 A3 E0 9D ED F5 F6 9F 67 79 E2 3B CB A9 81 3B 43 2C 68 4E E8 CA 64 E4 29 52 A4 1E BC D7 76 1B 15 94 FD 55 47 09 4F 7B 69 D5 FB DB 6B 7B D9 EB E6 99 AD 0C DF 86 B0 39 6C 27 83 C3 CA 51 A8 D4 54 52 D6 ED B6 D4 9B BD AD BB 6D BD 3D 4F 00 D4 74 DF 1F 7C 40 D5 D3 55 72 75 5D 43 51 2C E5 2D C6 E6 5E 4E 43 00 00 5F 5C 74 00 8A DD F1 07 C5 CF 8C 77 6D 61 A4 4F A8 4A F0 E9 F6 51 5A 45 62 F1 AC 90 11 0A ED 01 A2 70 51 B1 EE 0F 35 A3 F0 1B E2 ED A7 C3 DF 1A 8D 56 F9 A1 82 19 6E 51 96 61 9F DC B0 C8 C3 0F E2 8C 83 F3 2F 7C 0E 46 2B 9C F8 9F A8 4D 67 F1 16 F6 FE 49 ED 67 B6 B9 BD 6B 88 1E D2 43 E5 32 B3 16 F9 71 8E 3A 8F 5E 2B DA 74 A1 2C 47 D5 EA 41 7B AB DD BA BA F9 74 D3 67 D5 6F B3 36 C6 FB 0C 46 3A 18 4A D8 68 FB 28 47 9A 12 7F CC F4 69 2D 95 95 BA 9A F7 5E 1E FF 00 84 83 40 87 E2 1F 8D 74 95 F0 ED 94 D6 ED 0E 9D 73 61 6A 01 BE B9 47 2C 64 31 B6 54 2E 4E D2 10 28 E3 A7 15 CC 78 AB C6 3E 25 F1 7E B6 9A F7 8A F5 23 2B DB C0 91 C3 29 5D A3 CB 03 03 E5 1C 76 AD DF 88 5F 17 3C 3F E3 9F 0B E8 BE 1C B4 82 FA 33 A4 34 B8 82 E6 71 24 71 89 1C BB 6C 20 03 8D C4 E3 39 38 C0 C9 C6 4F 2F 0E B1 2A F8 92 D7 52 D1 F4 18 75 78 F4 F4 76 30 DC 47 B9 06 40 C6 40 C6 EC 12 78 39 1E D5 AE 11 37 4F 9E 71 D5 39 24 9F 45 7E 8D B7 BF 5D 6D B6 C9 1F 33 8C 94 E3 09 54 C5 52 D6 3C CA 2B F9 63 B2 D5 DF 59 2D F5 B7 6D 8C B9 7C FD 5B 52 9B 5D BF 8A 46 B4 E3 0A 99 50 C4 70 18 81 DB 8A F4 1D 23 C5 B7 56 5E 1D D3 F4 CD 45 52 4B 0B 59 DE 4B 78 E5 3C B3 3F 97 9F C0 6C 1C 7B 9F 5A E7 74 5D 51 AE 2C 67 BE BD 90 46 59 65 2E 8C 80 29 27 27 6E 31 C0 07 F9 53 BC 27 F0 EB C5 BF 12 B5 DD 36 DF 48 59 5D 02 C5 10 81 47 CC A5 C8 00 E3 B9 25 87 E9 5D 55 A9 53 9C 54 6A E8 A2 FB F9 3D BC F5 B1 F9 AE 6D 8D 86 2D 39 57 97 24 61 7F 4B 24 DA F9 F9 F5 3F A4 4F F8 24 57 81 B4 FF 00 06 FE C1 BE 0D BF B4 D4 7E D7 3F 88 12 6D 56 FA 75 89 51 4C AE E6 3C 2A A8 E0 04 89 17 EA 09 EF 45 7A 27 EC 47 F0 AA E7 E0 97 EC 99 E0 1F 85 D7 84 99 B4 AF 0E C2 B2 EE EA 19 F3 21 07 DC 17 C5 15 FC D9 9B 54 8D 5C D2 BC A2 EE B9 E5 6F 4B B4 BF 04 8F 2B 2D 87 B3 CB E9 46 D6 F7 57 96 EA FF 00 A9 57 F6 CF FD 98 ED 3F 6A 4F 84 53 78 31 6E D6 0D 46 D5 9A 6D 32 49 46 63 32 15 C1 56 F6 61 C6 7B 66 BF 1A BE 23 FC 38 D5 FE 1A E8 3E 22 F8 19 F1 1A 49 2C DB C2 D7 5F D9 71 5E A4 78 04 AA 0E 0E DE C0 F0 70 00 C8 AF DF 2A FC C9 FF 00 82 9E 7E CD 1A E7 82 3E 3D 5E FC 4C B0 B3 79 FC 31 E2 F8 8C B7 A0 9D CB 6F 76 7E FB 11 8F E2 39 EF C0 3D CD 7B 9C 3D 8A 9D 7A 72 C1 B7 AA F7 A1 D1 EF 79 2E CF BA 4F CC E9 8E 27 EA 15 B9 ED EE C9 A6 FC A5 1F 85 AB EC DA BC 7B 3D 2E AF 63 F1 CF C7 DE 17 D7 3C 3F E2 34 B1 BC B9 6B 98 3C E5 58 6F 12 26 11 90 48 C6 09 00 1E 2B B9 F8 B5 6D E2 AF 03 D9 BF FC 23 BA A5 C4 96 50 CE F6 77 32 A2 63 32 45 23 46 DF 43 95 35 7B F6 A2 8B E2 B7 86 AF 6C FC 15 E2 0D 4D EE BC 3D 63 2F 9B A6 10 81 B3 18 6E 09 71 D4 ED 03 8A 8F E2 BB EA 09 F1 0A DF 5F F0 B4 5A C5 CF 87 7C 47 B7 57 97 4C B8 1F 2C A6 4F 99 FE 5F E0 F9 8B 0E E7 8E B5 FA 8C 6A 55 AF 2A 13 9F 2B 4D 3D 34 B3 71 B3 77 D3 49 5B 65 B5 EF EA 7F 40 D2 CC B1 19 86 17 03 56 A4 61 28 49 4D B5 7D 1D B9 7B A5 69 5A FA 6C 9D FD 4F 2A D7 FC 71 AF EA F6 49 67 AA 5E CF 2A 23 96 DD 34 CC 70 30 06 00 27 03 A7 A5 6D 6A 17 9E 27 B8 F8 48 B3 78 C3 C1 B7 92 E9 AE E5 74 3D 73 FD 5B A3 0E 36 16 C1 12 C7 E8 08 C8 E8 18 00 00 B9 AA 7C 3A D4 3E 18 F8 A2 D7 5B F1 47 82 AE 6E 34 99 59 2F 2C 20 BF 9C 3A CF 01 01 B6 B3 A8 50 4E 0F 23 03 9F 5A EB BE 33 FE D6 91 FC 43 F0 F4 7E 0D D2 3C 2F 0E 9F A4 43 1E E4 B3 60 A4 A1 F4 1B 54 28 03 B6 00 E3 1D F9 3D CA 4E BF B3 95 0A 7E EB D7 4B 2E 57 D5 DD 3D FC 95 D3 D9 9D 39 8E 60 A7 1A 14 70 58 45 52 9C A5 CC E6 A4 92 85 BB 72 FD AE 8D 6D 64 D3 3E 7B 92 46 40 8A B1 33 34 8D 81 EE 6B D1 E0 FD 9E BC 5F AF 78 16 E3 E2 2D DE A1 05 AE 8B 65 6F 83 75 32 ED 69 64 00 16 8D 01 FB C5 49 20 9E C6 B0 3C 0F E3 5D 0F 45 F1 4C 03 5B D0 05 F6 9D 23 62 F2 DC C1 BD D0 E0 ED 78 C8 2A 43 03 8C 73 83 DC 1E 31 2F 8B FE 21 7C 47 BA F0 C5 97 81 B5 FD 52 E8 69 F6 A6 57 B7 B6 B8 52 A7 2E E4 B9 E7 AF CD 90 71 DC 11 DA AE 9F D6 67 5E A4 39 B4 56 B3 FC ED DF B5 BC D1 39 DE 2B 1E EA D3 C3 E0 D4 62 EE 9B 73 FE 5D 6F C8 BA C9 5B D1 5D 33 2F C3 D0 E8 B1 DD C6 96 5A 7A C8 C7 29 B6 42 48 6E BC 9E 6B A2 D4 3C 5D A4 EA 3A 85 AD C6 81 A5 DB E9 90 5A 59 2D BC 90 DB A0 0A F3 21 21 DC F7 24 F1 D4 D7 37 E1 1D 2B 5F D4 0C F0 78 63 4E 96 E2 EA 20 64 9B 62 7C B1 46 07 DE 63 D0 0A 96 D7 E1 FE A2 9E 08 9B 55 B7 D7 61 59 9E E5 DE 45 6C FC C3 A7 CB F8 E6 BD 2A D1 A1 19 AB EC B4 FB FC BC FA 1F 07 C4 70 8C BF 8B 3B 49 3B 59 BD EF 7D D7 E5 74 61 EA 97 97 BA D5 E5 DC 3A 3D D8 31 1B 82 66 06 3C 11 EB 83 9F 5A FA 93 FE 09 DA 75 CF 16 7E D6 3F 0F B4 5D 13 4A FE D2 BB 87 5F B4 9F 52 09 08 64 8E DA 20 14 6F 50 3E 6E 59 4F B1 00 F6 AF 9F 6C BC 16 9E 1B F0 CC 77 62 E6 37 92 48 4C 97 24 A9 27 3B BA 7F 2F CE BF 6D 7F E0 DE EF D8 57 C3 DE 01 F8 4C 7F 6C AF 12 69 68 35 6F 16 DB F9 1E 1F B7 92 D4 0F B2 DA 23 11 24 A0 9C 9C C9 20 2B DB 02 21 FD E3 5E 4F 12 66 D8 3C BF 2B 95 79 2B DA F1 8F 9C AD 64 9F E7 B7 43 F2 1C C9 CB 1D 4F EA AD DD C9 D9 3E C9 59 B6 FD 16 CB AB 69 1F A5 B4 51 45 7F 3A 9E B0 56 5F 8B FC 17 E1 4F 1F 68 73 78 6B C6 7A 05 B6 A5 63 70 85 65 B7 BA 8F 70 20 FA 1E AA 7D C6 0D 6A 51 55 09 CE 9C 94 A2 EC D7 54 29 46 32 56 6A E8 FC 75 FF 00 82 92 7E C4 87 E1 8F ED 05 AB E9 3A 5F 82 FE CD E0 8F 12 E9 3B B4 2D 47 73 C9 6F A6 CE A3 3B 36 3B 10 B8 FB A3 91 9C 66 BE 46 B6 B3 F8 91 AC 6A BA 97 C3 1F 1E B0 5D 4F 42 B5 8C 69 4F 02 ED 17 36 E8 36 E1 78 CF 41 B8 F2 7E F5 7F 46 1E 2E F0 5F 84 BC 7B A2 CB E1 DF 1A 78 76 CF 53 B2 99 4A C9 6F 79 00 75 20 F5 C6 7A 1F 71 CD 7C 3B FF 00 05 26 FF 00 82 5F 78 6B 5A F8 77 2F C6 2F D9 7B C2 37 90 F8 BF 42 5F 32 DB 48 B0 BE 08 B7 09 8F 9B 6B 48 AE 41 E3 25 4E E0 D9 C7 15 F7 B9 56 7F 85 C5 51 8E 16 BA E5 A8 EC 94 BA 73 77 6D BD 1B D9 E9 66 9B D5 68 74 E1 73 4C 5E 06 93 A5 51 F3 53 B6 8D DD B8 6B A4 AD AD D5 9F 2C AD AB 8D 9E F1 D7 F1 D3 E2 8F C4 BF 1A DB 78 56 E7 E1 FF 00 89 60 B7 BF B4 50 8B 17 DA 63 DC D6 8D 81 86 42 A4 10 7D 8E 47 B5 78 A5 AC 31 DD 6A B0 58 DD 07 2B 2C C1 08 8D 72 D8 EE 71 F4 AF AC FE 3C 7C 35 9A F7 C3 90 6A BE 22 F0 1E A1 A2 6B D7 0B B2 FF 00 4E 11 2C 69 F6 85 E2 5C 89 0A EC 1B 81 C1 2D D3 1C 57 CA 53 DC 47 A0 78 CE 0B A9 67 0A 90 5D 94 91 51 B2 53 07 04 EE 53 FA 8A FD 17 29 A9 07 86 94 61 0E 59 AD F7 B7 AA D7 67 E4 AC FC CF D8 B8 33 3B C1 55 CB 2A D3 A2 A2 A7 AD D2 D5 39 6A AE AC DA B3 6B 75 BE 8F 73 A8 F1 1E AB A4 69 1E 09 B4 D0 7C 17 E1 57 5B 3B 5D 59 EE E6 D7 1E CD BC EB 82 76 EC 57 76 C8 01 42 80 15 76 8E A7 19 26 B9 BF 13 78 CB FE 12 F0 F0 5C B4 97 46 D2 E2 67 B3 92 7C 07 4F 32 47 B8 94 7F BB E6 CB 21 03 B6 6A 7F 14 5D 6A D3 6A 37 3A 04 73 DF 44 85 B7 08 25 B9 65 B5 40 46 E4 60 01 C3 82 A4 30 24 03 82 38 15 CA EB 9A 00 F0 FE A0 B6 F6 F7 D7 12 CB 32 03 70 1D 36 6D 24 02 40 07 B6 30 41 EE 08 35 EC E1 68 BE 78 E8 9E ED 3B EB B7 5F F8 1A 1E 2D 4A F8 0A 54 E2 EB BF DF 73 CA 4A 57 72 69 CA DC CE EE D6 E8 AC AC AD A2 47 AC C7 F1 0F 46 F0 37 C2 BB AF 08 69 5A 85 AB DE 6B F0 45 24 AF A7 45 99 B9 45 3B 26 66 E1 15 72 40 55 DD B8 E7 95 C7 3C B0 D6 E2 D3 7C 1F 73 69 2A 46 E8 96 E7 CA DA 08 2C C7 A0 EB 59 FE 1F F0 C4 56 3A 74 2F 71 A8 C2 2C AF 53 3A 6D EC AD 91 0C 9B 9B CC 8A 42 01 21 81 C1 C6 0F 0E A7 BE 04 BF 0C BE 16 F8 CB E2 67 C4 6D 3B C0 BA 45 8D CE A9 79 79 A9 2C 16 F6 36 63 25 F2 FB 77 63 D3 DE A6 85 1A 31 8C F9 A5 77 7B B7 E9 A6 9E 96 B1 F2 B9 C5 7C 1A 95 4A D5 6A A6 EF CD 27 7D 5D BF 2D 3F E1 8B FF 00 B3 FE 81 AF 7C 4F F8 87 E1 7F 05 EA 31 4E D6 DA C6 AB 0D A2 C4 88 4F 9C 0C 8A 8D 93 EC 1B 90 39 03 9A FE AA FE 0E 7C 3A D0 BE 11 FC 2A F0 F7 C3 3F 0D 69 D0 DA 59 68 9A 44 16 90 C1 6E 0E C5 DA 80 31 19 E7 96 C9 E7 D6 BF 37 BF E0 93 1F F0 44 BF 88 3F B3 B7 C4 44 F8 D5 FB 45 5C 69 F1 1D 2F 53 6B 9F 0F F8 6F CB 17 2C 8E 77 8F 31 DC E0 21 DA C0 6D 50 72 46 49 E0 63 F5 1A BF 24 E3 CC F7 0F 99 E2 29 E1 F0 D2 4E 10 BB 76 7A 36 ED 6E 9B A5 BE EB B3 3E 41 BA 38 AC C6 78 9A 50 E5 85 94 63 75 66 FA C9 DB 74 9B B2 D5 26 ED 7D AC 14 51 45 7E 7E 74 85 14 51 40 05 14 51 40 1E 6F F1 D3 F6 4C F8 0D FB 46 68 AF A1 FC 51 F0 1D A5 DC 6E 24 CC D0 C2 89 2E F6 00 6F 2D B7 2C C3 1C 67 23 D8 D7 CA BE 2E FF 00 83 73 FF 00 E0 9E 3E 31 97 CF BB FF 00 84 DA D1 B6 E3 36 1A E5 BC 7F 8E 0D B1 14 51 5E 9E 1F 39 CD B0 91 51 A3 5E 51 4B B3 FF 00 87 FB B6 F2 16 1D 7D 52 B3 AB 41 B8 49 EE D3 6A FF 00 73 4B F0 34 A7 FF 00 83 7D 7F E0 9F 77 5A 3C 5A 55 CD 9F 8B E4 78 AD 92 06 BD 7D 72 23 34 8A 8A 15 4B 1F 23 6E 42 80 38 03 A5 64 6A BF F0 6E 47 FC 13 E3 59 FB 33 5F 6A 7F 10 1A 4B 48 CC 50 4D FF 00 09 05 B1 71 19 E8 84 9B 53 B8 03 92 33 92 37 63 3B 42 80 51 5A AE 21 CF 22 EE B1 33 BF AF FC 01 BE 69 4A ED B6 FD 5F F9 95 BC 33 FF 00 06 DB 7F C1 3E BC 2D 61 79 A6 5A 78 8F E2 3D C4 17 B7 71 DC 49 1D DF 88 6D 1C 24 88 18 65 31 68 36 EE 0C 03 7A 84 4F 4A FA 23 F6 67 FF 00 82 6B 7E C7 FF 00 B2 6E A8 7C 43 F0 97 E1 6C 0B AA 1B 64 84 EA BA 99 17 13 80 BD 48 62 A0 29 63 C9 2A 07 3D 31 45 14 AB E7 F9 D6 26 9C A1 57 11 36 A5 BA BE FB 6F 64 BB 23 9A A6 0F 0D 56 A4 6A 4E 29 CA 3B 37 77 F9 BF CD 33 DE 28 A2 8A F2 0E 90 A2 8A 28 03 FF D9]|\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(images.select('content').show(1,False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.  [&#9650;](#toc0_) <a id='toc4_'></a>Build model for feature extraction and broadcast its weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-17 20:02:32.419677: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# DL or load mobilenetV2\n",
    "model = MobileNetV2(\n",
    "    weights='imagenet',\n",
    "    include_top=True,\n",
    "    input_shape=(224, 224, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model without the last layer\n",
    "new_model = Model(\n",
    "    inputs=model.input,\n",
    "    outputs=model.layers[-2].output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)                 (None, 112, 112, 32  864         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalization)  (None, 112, 112, 32  128         ['Conv1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)              (None, 112, 112, 32  0           ['bn_Conv1[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (Depth  (None, 112, 112, 32  288        ['Conv1_relu[0][0]']             \n",
      " wiseConv2D)                    )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN (Ba  (None, 112, 112, 32  128        ['expanded_conv_depthwise[0][0]']\n",
      " tchNormalization)              )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_relu (  (None, 112, 112, 32  0          ['expanded_conv_depthwise_BN[0][0\n",
      " ReLU)                          )                                ]']                              \n",
      "                                                                                                  \n",
      " expanded_conv_project (Conv2D)  (None, 112, 112, 16  512        ['expanded_conv_depthwise_relu[0]\n",
      "                                )                                [0]']                            \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (Batc  (None, 112, 112, 16  64         ['expanded_conv_project[0][0]']  \n",
      " hNormalization)                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)        (None, 112, 112, 96  1536        ['expanded_conv_project_BN[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNormal  (None, 112, 112, 96  384        ['block_1_expand[0][0]']         \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)     (None, 112, 112, 96  0           ['block_1_expand_BN[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D)    (None, 113, 113, 96  0           ['block_1_expand_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_depthwise (DepthwiseCo  (None, 56, 56, 96)  864         ['block_1_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (BatchNor  (None, 56, 56, 96)  384         ['block_1_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (ReLU)  (None, 56, 56, 96)   0           ['block_1_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)       (None, 56, 56, 24)   2304        ['block_1_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_1_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_1_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_2_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_2_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_2_depthwise (DepthwiseCo  (None, 56, 56, 144)  1296       ['block_2_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (BatchNor  (None, 56, 56, 144)  576        ['block_2_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (ReLU)  (None, 56, 56, 144)  0           ['block_2_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)       (None, 56, 56, 24)   3456        ['block_2_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_2_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_add (Add)              (None, 56, 56, 24)   0           ['block_1_project_BN[0][0]',     \n",
      "                                                                  'block_2_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_2_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_3_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_3_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_3_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D)    (None, 57, 57, 144)  0           ['block_3_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_3_depthwise (DepthwiseCo  (None, 28, 28, 144)  1296       ['block_3_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (BatchNor  (None, 28, 28, 144)  576        ['block_3_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (ReLU)  (None, 28, 28, 144)  0           ['block_3_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)       (None, 28, 28, 32)   4608        ['block_3_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_3_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_3_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_4_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_4_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_4_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_4_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_4_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_4_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_4_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_4_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_add (Add)              (None, 28, 28, 32)   0           ['block_3_project_BN[0][0]',     \n",
      "                                                                  'block_4_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_4_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_5_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_5_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_5_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_5_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_5_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_5_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_5_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_5_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_add (Add)              (None, 28, 28, 32)   0           ['block_4_add[0][0]',            \n",
      "                                                                  'block_5_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_5_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_6_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_6_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D)    (None, 29, 29, 192)  0           ['block_6_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_6_depthwise (DepthwiseCo  (None, 14, 14, 192)  1728       ['block_6_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (BatchNor  (None, 14, 14, 192)  768        ['block_6_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (ReLU)  (None, 14, 14, 192)  0           ['block_6_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)       (None, 14, 14, 64)   12288       ['block_6_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_6_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_6_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_7_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_7_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_7_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_7_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_7_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_7_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_7_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_7_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_add (Add)              (None, 14, 14, 64)   0           ['block_6_project_BN[0][0]',     \n",
      "                                                                  'block_7_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_7_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_8_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_8_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_8_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_8_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_8_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_8_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_8_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_8_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_add (Add)              (None, 14, 14, 64)   0           ['block_7_add[0][0]',            \n",
      "                                                                  'block_8_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_8_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_9_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_9_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_9_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_9_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_9_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_9_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_9_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_9_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_add (Add)              (None, 14, 14, 64)   0           ['block_8_add[0][0]',            \n",
      "                                                                  'block_9_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)       (None, 14, 14, 384)  24576       ['block_9_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchNorma  (None, 14, 14, 384)  1536       ['block_10_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU)    (None, 14, 14, 384)  0           ['block_10_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_depthwise (DepthwiseC  (None, 14, 14, 384)  3456       ['block_10_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (BatchNo  (None, 14, 14, 384)  1536       ['block_10_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0          ['block_10_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)      (None, 14, 14, 96)   36864       ['block_10_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_10_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_10_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_10_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_11_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_11_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_11_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_11_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_11_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_11_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_11_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_11_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_11_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_add (Add)             (None, 14, 14, 96)   0           ['block_10_project_BN[0][0]',    \n",
      "                                                                  'block_11_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_11_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_12_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_12_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_12_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_12_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_12_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_12_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_12_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_12_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_12_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_add (Add)             (None, 14, 14, 96)   0           ['block_11_add[0][0]',           \n",
      "                                                                  'block_12_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_12_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_13_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_13_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2D)   (None, 15, 15, 576)  0           ['block_13_expand_relu[0][0]']   \n",
      "                                                                                                  \n",
      " block_13_depthwise (DepthwiseC  (None, 7, 7, 576)   5184        ['block_13_pad[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (BatchNo  (None, 7, 7, 576)   2304        ['block_13_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)   0           ['block_13_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)      (None, 7, 7, 160)    92160       ['block_13_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_13_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_13_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_13_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_14_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_14_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_14_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_14_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_14_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_14_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_14_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_14_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_14_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_add (Add)             (None, 7, 7, 160)    0           ['block_13_project_BN[0][0]',    \n",
      "                                                                  'block_14_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_14_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_15_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_15_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_15_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_15_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_15_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_15_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_15_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_15_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_15_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_add (Add)             (None, 7, 7, 160)    0           ['block_14_add[0][0]',           \n",
      "                                                                  'block_15_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_15_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_16_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_16_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_16_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_16_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_16_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_16_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)      (None, 7, 7, 320)    307200      ['block_16_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_16_project_BN (BatchNorm  (None, 7, 7, 320)   1280        ['block_16_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)                (None, 7, 7, 1280)   409600      ['block_16_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)  5120        ['Conv_1[0][0]']                 \n",
      "                                                                                                  \n",
      " out_relu (ReLU)                (None, 7, 7, 1280)   0           ['Conv_1_bn[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 1280)        0           ['out_relu[0][0]']               \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,257,984\n",
      "Trainable params: 2,223,872\n",
      "Non-trainable params: 34,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a broadcast object to broadcast the model weights to\n",
    "# each worker.\n",
    "broadcast_weights = sc.broadcast(new_model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.broadcast.Broadcast at 0x7fc595aecc70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broadcast_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.  [&#9650;](#toc0_) <a id='toc5_'></a>Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    \"\"\"\n",
    "    Returns a MobileNetV2 model with top layer removed \n",
    "    and set weights to the broadcasted pretrained weights.\n",
    "    \"\"\"\n",
    "    model = MobileNetV2(weights='imagenet',\n",
    "                        include_top=True,\n",
    "                        input_shape=(224, 224, 3))\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    new_model = Model(inputs=model.input,\n",
    "                      outputs=model.layers[-2].output)\n",
    "    new_model.set_weights(broadcast_weights.value)\n",
    "    return new_model\n",
    "\n",
    "\n",
    "def preprocess(content):\n",
    "    \"\"\"\n",
    "    - Takes raw image bytes and transforms it to a pillow image.\n",
    "    - Resize the images to the Mobilenet input size \n",
    "    and preprocess the pixel values.    \n",
    "    \"\"\"\n",
    "    img = Image.open(io.BytesIO(content)).resize([224, 224])\n",
    "    arr = img_to_array(img)\n",
    "    return preprocess_input(arr)\n",
    "\n",
    "def featurize_series(model, content_series):\n",
    "    \"\"\"\n",
    "    Featurize a pd.Series of images using the input model.\n",
    "    :return: a pd.Series of image features\n",
    "    \"\"\"\n",
    "    input = np.stack(content_series.map(preprocess))\n",
    "    preds = model.predict(input)\n",
    "    # For some layers, the output features can be multi-dimensional tensors.\n",
    "    # Thus, we flatten the feature tensors to vectors for easier storage in Spark DataFrames.\n",
    "    output = [p.flatten() for p in preds]\n",
    "    return pd.Series(output)\n",
    "\n",
    "\n",
    "@pandas_udf('array<float>')\n",
    "def featurize_udf(\n",
    "    content_series_iter: Iterator[pd.Series]\n",
    ") -> Iterator[pd.Series]:\n",
    "    '''\n",
    "    This method is a Scalar Iterator pandas UDF wrapping our featurization function.\n",
    "    The decorator specifies that this returns a Spark DataFrame column of type ArrayType(FloatType).\n",
    "    \n",
    "    :param content_series_iter: This argument is an iterator over batches of data, where each batch\n",
    "                                is a pandas Series of image data.\n",
    "    '''\n",
    "    # With Scalar Iterator pandas UDFs, we can load the model once and then re-use it\n",
    "    # for multiple data batches.  This amortizes the overhead of loading big models.\n",
    "    model = model_fn()\n",
    "    for content_series in content_series_iter:\n",
    "        yield featurize_series(model, content_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-17 20:02:46.092787: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-07-17 20:02:46.367748: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-07-17 20:02:46.463441: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-07-17 20:02:46.502024: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-07-17 20:02:46.564929: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-07-17 20:02:46.651930: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-07-17 20:02:46.666632: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-07-17 20:02:46.866554: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-07-17 20:02:48.279928: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-07-17 20:02:48.403894: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-07-17 20:02:48.646632: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-07-17 20:02:48.686860: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-07-17 20:02:48.836766: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-07-17 20:02:48.845629: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-07-17 20:02:48.886448: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-07-17 20:02:48.993448: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-07-17 20:02:54.365790: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14450688 exceeds 10% of free system memory.\n",
      "2023-07-17 20:02:54.394978: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14709888 exceeds 10% of free system memory.\n",
      "2023-07-17 20:02:54.412791: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14709888 exceeds 10% of free system memory.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "2023-07-17 20:03:02.623877: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-07-17 20:03:02.655210: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                 (9 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (11 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "2023-07-17 20:03:05.662814: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-07-17 20:03:05.734800: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-07-17 20:03:08.634807: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-07-17 20:03:08.872058: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "2023-07-17 20:03:10.996189: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-07-17 20:03:11.382224: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step                (17 + 9) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (18 + 9) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (20 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                (21 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (22 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (23 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step                (27 + 8) / 300]\n",
      "2023-07-17 20:03:23.589164: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "1/1 [==============================] - ETA: 0sWARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f134f666050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f134f622050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "2023-07-17 20:03:25.771987: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14709888 exceeds 10% of free system memory.\n",
      "2023-07-17 20:03:25.849762: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14450688 exceeds 10% of free system memory.\n",
      "2023-07-17 20:03:25.884315: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14709888 exceeds 10% of free system memory.\n",
      "2023-07-17 20:03:25.996020: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                (31 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (32 + 8) / 300]\n",
      "2023-07-17 20:03:26.630965: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14450688 exceeds 10% of free system memory.\n",
      "2023-07-17 20:03:26.664362: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14709888 exceeds 10% of free system memory.\n",
      "2023-07-17 20:03:26.722242: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14450688 exceeds 10% of free system memory.\n",
      "2023-07-17 20:03:26.757160: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14709888 exceeds 10% of free system memory.\n",
      "1/1 [==============================] - 3s 3s/step                (33 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f12dc1a6b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f12be462170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f12be18ff40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step                (39 + 9) / 300]\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f12be45a170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f135389de10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "2023-07-17 20:03:40.012194: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14450688 exceeds 10% of free system memory.\n",
      "2023-07-17 20:03:40.041937: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14709888 exceeds 10% of free system memory.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f132b75b880> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step                (45 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (46 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (47 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "2023-07-17 20:03:41.572989: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14450688 exceeds 10% of free system memory.\n",
      "2023-07-17 20:03:41.616652: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14709888 exceeds 10% of free system memory.\n",
      "1/1 [==============================] - ETA: 0sWARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f134f9c7880> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "2023-07-17 20:03:46.065724: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-07-17 20:03:47.118682: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14450688 exceeds 10% of free system memory.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "2023-07-17 20:03:47.626137: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14450688 exceeds 10% of free system memory.\n",
      "2023-07-17 20:03:47.682043: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f133d95ea70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                (54 + 8) / 300]\n",
      "2023-07-17 20:03:48.595885: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14709888 exceeds 10% of free system memory.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f134f9e0700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "2023-07-17 20:03:48.846497: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14450688 exceeds 10% of free system memory.\n",
      "2023-07-17 20:03:48.865536: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14709888 exceeds 10% of free system memory.\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "2023-07-17 20:03:49.374148: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-07-17 20:03:51.115759: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step                (58 + 8) / 300]\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f134f9e1b40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f134f9e11b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step                (62 + 8) / 300]\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f12de022560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 3s 3s/step                (64 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (65 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (66 + 8) / 300]\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f133d9feef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step                (68 + 8) / 300]\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f133d9feef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step                (70 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (71 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (72 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (73 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (74 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                (76 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step                (78 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step                (80 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (81 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (82 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (83 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (84 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step                (86 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (87 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (88 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (89 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                (90 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (92 + 8) / 300]\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f12d04ef2e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step                (95 + 8) / 300]\n",
      "1/1 [==============================] - ETA: 0sWARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f12be4cb880> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step                (97 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (98 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (99 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (100 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (101 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (102 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (103 + 8) / 300]\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f13537dea70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step               (105 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (107 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (108 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (109 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (110 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (111 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (112 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (113 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (114 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (115 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (116 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (117 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step               (119 + 8) / 300]\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f13538a5b40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 3s 3s/step               (120 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (121 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (123 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (124 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (125 + 8) / 300]\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f13537b25f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step               (128 + 8) / 300]\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f12be743520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (131 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (132 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (133 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step               (135 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (136 + 8) / 300]\n",
      "2023-07-17 20:05:04.132751: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - ETA: 0sWARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f134fa7f2e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (139 + 8) / 300]\n",
      "2023-07-17 20:05:06.598329: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step               (141 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (142 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (143 + 8) / 300]\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1353853880> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (145 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (146 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (147 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step               (149 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (150 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (151 + 8) / 300]\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f134faef760> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (153 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step               (155 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (156 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (157 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (158 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (159 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (160 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (161 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (162 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (163 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (164 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (165 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (166 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (167 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (168 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (169 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (171 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (172 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (173 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (174 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (175 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (176 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (177 + 8) / 300]\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f13538539a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (179 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (180 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (181 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (182 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (183 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (184 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (185 + 8) / 300]\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f134fa52f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step               (187 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (188 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (189 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (190 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (191 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (192 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (193 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (194 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (195 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (196 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (197 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (198 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (199 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (200 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (201 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (203 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step               (205 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (206 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (207 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (208 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (209 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (210 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (211 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (212 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (213 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (214 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (215 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step>              (221 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step>              (222 + 8) / 300]\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f12d0443760> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step                   (0 + 1) / 1]\n",
      "1/1 [==============================] - 2s 2s/step                 (0 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                 (1 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step                 (6 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                 (8 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                 (9 + 8) / 300]\n",
      "2023-07-17 20:07:23.546802: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                (11 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step                (13 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (14 + 8) / 300]\n",
      "2023-07-17 20:07:26.710189: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                (16 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (17 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (18 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (19 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step                (21 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (22 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (23 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                (24 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step                (27 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (28 + 8) / 300]\n",
      "2023-07-17 20:07:39.722999: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14709888 exceeds 10% of free system memory.\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step                (30 + 8) / 300]\n",
      "2023-07-17 20:07:44.844312: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14450688 exceeds 10% of free system memory.\n",
      "2023-07-17 20:07:44.865867: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14709888 exceeds 10% of free system memory.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "2023-07-17 20:07:45.295607: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14450688 exceeds 10% of free system memory.\n",
      "2023-07-17 20:07:45.328927: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14709888 exceeds 10% of free system memory.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                (33 + 8) / 300]\n",
      "2023-07-17 20:07:45.663593: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14450688 exceeds 10% of free system memory.\n",
      "1/1 [==============================] - 3s 3s/step                (34 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (34 + 9) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (36 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (37 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (38 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (39 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step                (41 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                (43 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (44 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (45 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (46 + 8) / 300]\n",
      "2023-07-17 20:07:59.862821: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14450688 exceeds 10% of free system memory.\n",
      "2023-07-17 20:07:59.881278: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14709888 exceeds 10% of free system memory.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "2023-07-17 20:08:00.686229: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14450688 exceeds 10% of free system memory.\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "2023-07-17 20:08:01.189552: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14709888 exceeds 10% of free system memory.\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step                (51 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step                (53 + 8) / 300]\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f132b7cf880> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "2023-07-17 20:08:07.658567: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14450688 exceeds 10% of free system memory.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                (56 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step                (58 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (59 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (60 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (61 + 8) / 300]\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f133d95ea70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step                (63 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (64 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (65 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (66 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (66 + 9) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (68 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (69 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (70 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (71 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (72 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (73 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (74 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (75 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step                (77 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (78 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (79 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                (80 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (81 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (83 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (84 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step                (86 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (87 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (88 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step                (89 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (91 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (92 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (93 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (94 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (95 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                (96 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (98 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (99 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (100 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (101 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (102 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (103 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (104 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (107 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (108 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (109 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (110 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (111 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (112 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (114 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (115 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (116 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (117 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (118 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (119 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (120 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (122 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step               (124 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (125 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (126 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (127 + 8) / 300]\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f134f95e320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (129 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (130 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step               (132 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (133 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f134f65fd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (136 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (138 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step               (141 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step               (143 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (145 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (146 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step               (149 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (150 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (151 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (152 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (154 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (155 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step               (157 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (158 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (159 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step               (161 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (163 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (164 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (165 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (166 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (167 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (168 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step               (169 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (171 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (173 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (174 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (175 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (176 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (177 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (178 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (179 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (180 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (181 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step               (183 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (184 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (185 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (186 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (187 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (188 + 8) / 300]\n",
      "2023-07-17 20:10:05.441516: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "1/1 [==============================] - 3s 3s/step               (189 + 8) / 300]\n",
      "2023-07-17 20:10:09.192304: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (191 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (192 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (193 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (194 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (195 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (196 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (197 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (198 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (199 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (200 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (201 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step               (203 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (204 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (205 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (206 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (208 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (209 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (210 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (211 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (212 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (213 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (216 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step>              (217 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step>              (218 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 1s 1s/step                   (0 + 1) / 1]\n",
      "2023-07-17 20:11:31.702400: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14450688 exceeds 10% of free system memory.\n",
      "2023-07-17 20:11:31.759575: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14709888 exceeds 10% of free system memory.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "2023-07-17 20:11:41.387572: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                 (9 + 8) / 300]\n",
      "1/1 [==============================] - ETA: 0sWARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f13537b0430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                (11 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step                (14 + 8) / 300]\n",
      "2023-07-17 20:11:44.782856: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                (16 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f12be346710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 3s 3s/step                (19 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (20 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step                (22 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (23 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step                (25 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step                (29 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step                (31 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (32 + 8) / 300]\n",
      "2023-07-17 20:12:05.569741: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14450688 exceeds 10% of free system memory.\n",
      "2023-07-17 20:12:05.610050: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14709888 exceeds 10% of free system memory.\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step                (34 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (35 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (37 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (38 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (39 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                (41 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step                (43 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step                (45 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step                (47 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (48 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (49 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "2023-07-17 20:12:21.396900: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 14450688 exceeds 10% of free system memory.\n",
      "1/1 [==============================] - 3s 3s/step                (51 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step                (54 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (55 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                (57 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (58 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (59 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step                (60 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (61 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (63 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (64 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (65 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step                (68 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (69 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step                (71 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (72 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (73 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step                (75 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step                (76 + 8) / 300]\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f134f95ecb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step                (79 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (80 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step                (82 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (83 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f132b96b9a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step                (87 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                (88 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (90 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (91 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (92 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 4s 4s/step                (94 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (95 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                (97 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (98 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (99 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (100 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step               (102 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (103 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (104 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (106 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step               (108 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (109 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step               (111 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (112 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (113 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (114 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (115 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (116 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (117 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (118 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (119 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (120 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (122 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (123 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step               (125 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (126 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (127 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (129 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (131 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (132 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (133 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (134 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (135 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (136 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (137 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step               (139 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (140 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (141 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (142 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (143 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (144 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (145 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (147 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (148 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (149 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (150 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (151 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (152 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (154 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step               (155 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (156 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (158 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (159 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (160 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (162 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (164 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step               (166 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (167 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (168 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (169 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (171 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (172 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (174 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (175 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (177 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step               (181 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (182 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (183 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (184 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (186 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (188 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (190 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (191 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (192 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (195 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step               (198 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (199 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (202 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (203 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step               (206 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (207 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (209 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (210 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (211 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (214 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step>              (219 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step>              (222 + 8) / 300]\n",
      "23/07/17 20:15:56 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "1/1 [==============================] - 2s 2s/step                 (0 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "23/07/17 20:16:04 WARN MemoryManager: Total allocation exceeds 95,00% (1 020 054 720 bytes) of heap memory\n",
      "Scaling row group sizes to 95,00% for 8 writers\n",
      "1/1 [==============================] - 2s 2s/step                 (8 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step                 (9 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (16 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                (18 + 9) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (19 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                (24 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                (26 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (28 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (30 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step                (32 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                (34 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step                (40 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (41 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                (42 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (44 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (45 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step                (48 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (49 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                (50 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step                (52 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (53 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step                (56 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                (58 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                (60 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (62 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step                (64 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                (67 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (69 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step                (72 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (73 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (74 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                (75 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step                (78 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step                (80 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                (82 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (83 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step                (84 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step                (85 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                (88 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (89 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                (92 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                (93 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step                (96 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (97 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step                (98 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (101 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step               (103 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (104 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (105 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (106 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (107 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (109 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (111 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (112 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (113 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (114 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (115 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (119 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (120 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (121 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (122 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (123 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (126 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step               (128 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (129 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (130 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (134 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (135 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (136 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (137 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (139 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (142 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (143 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (144 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (145 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (146 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (147 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step               (149 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (150 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step               (152 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (153 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (154 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (155 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (156 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (157 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (158 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (159 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (160 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (161 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (163 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (164 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step               (166 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (167 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (168 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (169 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (172 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step               (174 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (176 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (177 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (179 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (180 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (181 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (182 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step               (184 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (186 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (187 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step               (189 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (190 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (191 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (192 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (193 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (195 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (196 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (197 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (199 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (200 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (202 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (204 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (205 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step               (207 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (208 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step               (209 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (210 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step               (211 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step               (214 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step               (215 + 8) / 300]\n",
      "1/1 [==============================] - 3s 3s/step>              (221 + 8) / 300]\n",
      "1/1 [==============================] - 2s 2s/step>              (222 + 8) / 300]\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Build a DF with the path, label and features of each image\n",
    "features_df = (\n",
    "    images\n",
    "    .repartition(300)\n",
    "    .select(\n",
    "        col(\"path\"),\n",
    "        col(\"label\"),\n",
    "        featurize_udf(\"content\").alias(\"features\")\n",
    "   )\n",
    ")\n",
    "\n",
    "#MLLib needs some post processing of the features column format\n",
    "list_to_vector_udf = udf(lambda l: Vectors.dense(l), VectorUDT())\n",
    "\n",
    "features_df = (\n",
    "    features_df\n",
    "    .select(\n",
    "        col(\"path\"),  \n",
    "        col(\"label\"),\n",
    "        list_to_vector_udf(features_df[\"features\"]).alias(\"features\")\n",
    "   )\n",
    ")\n",
    "\n",
    "# Define a pipeline to Standardize the features\n",
    "# and compute the PCA projection onto the 300 first PCs.\n",
    "scaler = StandardScaler(\n",
    "    inputCol=\"features\",\n",
    "    outputCol=\"scaled_features\",\n",
    "    withStd=True,\n",
    "    withMean=True\n",
    ")\n",
    "\n",
    "pca = PCA(\n",
    "    k=300,\n",
    "    inputCol=scaler.getOutputCol(),\n",
    "    outputCol=\"pca_features\",\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(stages=[scaler , pca])\n",
    "model = pipeline.fit(features_df)\n",
    "features_df = model.transform(features_df)\n",
    "\n",
    "# Write results\n",
    "(\n",
    "    features_df\n",
    "    .drop('scaled_features')\n",
    "    .write.mode(\"overwrite\")\n",
    "    .parquet(RESULT_PATH)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am not going for optimization right now, but it is not fast... It took ~17 minutes to compute the features and its PCA projection for 50 images."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.  [&#9650;](#toc0_) <a id='toc6_'></a>Loading results computed locally with spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 4)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(RESULT_PATH, engine='pyarrow')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['path', 'label', 'features', 'pca_features'], dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0, 'features'][\"values\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0, 'pca_features'][\"values\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.25521841e+00,  1.60126250e+00,  4.83094892e+00, -4.08174443e+00,\n",
       "       -2.16043178e+00,  9.56921187e+00,  2.19970715e-01, -6.20291185e+00,\n",
       "        3.08297696e+00,  5.65644473e+00, -4.72838495e+00,  1.09280383e+00,\n",
       "       -3.52825095e+00,  1.80234683e-01, -7.04883818e-01,  4.82799149e+00,\n",
       "       -2.03436723e+00,  1.76621269e+00,  1.13826690e+00,  9.29235301e+00,\n",
       "        4.20503896e-01,  1.89228250e-01, -6.25211537e-01, -2.04012120e+00,\n",
       "        1.95053092e+00, -1.35374726e+00,  3.48203758e+00,  1.95097982e+00,\n",
       "       -8.17487136e-01,  9.59395738e-01,  2.18300538e+00,  1.03877231e+00,\n",
       "        5.70958835e-01,  3.34160743e+00, -2.08947962e+00,  1.44429154e+00,\n",
       "        8.11047316e-01,  3.37691675e-01,  1.99258905e+00, -1.42532019e+00,\n",
       "        1.53364691e+00, -3.89652096e+00,  4.02096186e+00, -2.79418830e+00,\n",
       "       -4.75675641e-01,  1.65751112e+00, -1.99288612e+00, -4.74866438e-01,\n",
       "        7.01606043e-01,  6.76222252e-01,  3.61652621e-01,  1.50028329e+00,\n",
       "        2.07130259e+00, -3.61769303e+00, -1.96294701e+00,  4.20466599e-01,\n",
       "       -1.90689791e+00,  4.91105849e-01, -6.33045408e-03, -3.35296486e-01,\n",
       "       -1.80499119e+00,  5.72584559e-01,  2.61304679e+00, -8.43007509e-01,\n",
       "        1.59530590e+00, -4.12351107e-01,  1.60556495e+00,  9.30074331e-01,\n",
       "        2.63995566e+00,  2.89928392e-02, -1.03693155e+00,  1.65259549e+00,\n",
       "        3.79772370e-01, -4.69757217e-01,  2.11959785e+00, -2.75918576e+00,\n",
       "       -6.88785033e-01, -2.43444808e+00, -4.10450712e-01, -1.63973268e+00,\n",
       "        2.66397799e-01,  1.78243579e+00,  9.59142313e-01,  1.04543830e+00,\n",
       "       -1.22489079e+00,  2.48235021e+00, -9.74696893e-01,  3.72504536e+00,\n",
       "        4.98021233e+00, -7.24141810e-01, -6.91550694e-01, -4.58461112e-01,\n",
       "       -3.64566853e-01,  1.13785524e+00, -2.45795037e+00, -2.74814192e+00,\n",
       "        2.98152858e-01, -1.83720740e+00,  2.63988602e-02,  1.82397111e+00,\n",
       "        1.59564162e+00,  6.40305503e-01,  8.41344539e-01,  2.93035348e-02,\n",
       "        6.67298096e-01,  5.58309483e-02, -4.79885738e-01, -6.57276647e-01,\n",
       "        1.23198544e+00,  9.40116210e-01, -1.16316481e+00, -1.09541237e+00,\n",
       "        1.64126134e+00,  2.91227833e-01, -1.06852062e+00,  1.42527689e+00,\n",
       "       -4.86146183e-01,  2.62743669e-01, -1.52863344e+00, -9.40331161e-01,\n",
       "       -5.33951429e-02,  2.38201088e-01, -5.40410457e-01,  6.55529118e-01,\n",
       "       -1.35659355e+00, -4.05665563e-01,  2.13614410e+00, -3.91590656e-01,\n",
       "       -4.39719999e-01,  1.55592840e+00,  7.46868853e-01,  2.00237833e+00,\n",
       "       -5.58457568e-01, -9.36860182e-01,  3.47121506e-02, -7.98550447e-01,\n",
       "       -4.82562076e-01, -4.50870219e-01,  4.00767926e-01,  1.30992985e-01,\n",
       "       -5.30441099e-01,  2.72571972e-01, -1.25476319e+00, -4.20565623e-01,\n",
       "       -7.40533363e-01,  6.35386976e-01,  4.58019510e-01, -1.76921100e+00,\n",
       "        3.42344915e-01, -3.56363243e-01,  9.87899274e-01, -1.00128731e+00,\n",
       "        6.66457844e-01,  4.91092974e-01, -8.37610767e-01,  5.05419823e-01,\n",
       "        5.11995243e-01, -3.35207167e-01,  7.40738269e-01, -1.29699724e-01,\n",
       "        5.65203875e-01,  2.38770158e-01,  7.84697636e-01, -1.18944390e+00,\n",
       "        1.07348448e+00, -1.19756328e+00,  7.04366515e-01,  8.80510540e-01,\n",
       "       -6.82190231e-01, -9.04786991e-01,  1.49098105e+00,  1.20383719e-01,\n",
       "        3.88336836e-01,  7.56327817e-01, -4.35810720e-01,  3.56939739e-01,\n",
       "        1.16406195e-01,  1.00478218e+00, -5.87513357e-01, -6.67467822e-01,\n",
       "       -8.80997026e-01,  6.97993602e-01,  2.34713659e-01,  1.18274540e+00,\n",
       "       -8.80550280e-01, -1.84380714e-01,  7.50416747e-01,  2.76041134e-01,\n",
       "       -5.94745194e-01,  5.28452505e-01,  5.23912612e-01,  3.40759347e-01,\n",
       "       -3.61848216e-01,  5.83452032e-01, -1.21220395e+00, -3.26037956e-02,\n",
       "        6.24697993e-01, -1.35888857e+00,  4.33089596e-01,  2.85524204e-01,\n",
       "        1.26185396e+00,  1.67578272e-01, -3.62461610e-01,  1.16553204e+00,\n",
       "       -3.36773249e-01,  1.76326567e-01,  4.42402220e-01, -6.03330487e-01,\n",
       "       -2.40407382e-01, -3.32523114e-01,  9.28221571e-01,  1.94734616e-02,\n",
       "       -1.19357010e-01,  4.35629473e-01, -7.31753474e-01,  8.40373335e-01,\n",
       "       -9.33862651e-01, -3.41387373e-01, -1.71428877e-01, -8.85628125e-01,\n",
       "        5.41657733e-01,  7.97109822e-01,  1.15069161e-01,  4.39703290e-01,\n",
       "       -1.36782862e+00,  3.11715808e-01, -5.96013379e-01,  7.34324061e-01,\n",
       "        6.64501385e-01,  1.64333203e-01,  9.04623031e-01,  1.07300364e+00,\n",
       "       -1.73127282e-01,  4.42167631e-02, -4.70402562e-01,  2.96656212e-01,\n",
       "        1.18382048e+00,  2.35406054e-01,  1.19335262e+00,  1.44241646e+00,\n",
       "       -9.84969856e-01, -9.54030448e-02, -1.79344109e+00, -9.00106969e-01,\n",
       "        1.31732417e+00,  4.35569161e-01, -1.12526437e+00,  4.52088304e-02,\n",
       "        4.29623106e-03, -4.64477341e-01, -1.18789885e+00,  3.15627205e-01,\n",
       "        9.42465022e-01, -1.19406753e-01, -1.52097599e-01,  6.27484288e-01,\n",
       "        6.08374356e-01,  2.89181498e-01,  1.26803159e+00,  1.97933446e-01,\n",
       "       -2.79329462e-01, -1.02182656e+00, -5.15342820e-01,  4.88820043e-01,\n",
       "       -1.19654989e+00,  5.96976634e-01, -6.79238690e-02,  1.76910922e-01,\n",
       "       -2.33977620e-01,  1.29982008e-01, -1.37548640e-01, -4.16662388e-01,\n",
       "       -1.69870855e+00, -3.21013704e-02,  1.18745619e+00, -3.46460382e-01,\n",
       "        1.53867962e+00, -4.96250268e-02, -3.37550334e-01, -1.76506512e-01,\n",
       "       -1.10991048e-01,  4.69679504e-01,  9.63478732e-01,  6.30812818e-01,\n",
       "       -3.63785787e-01,  2.74037100e-01, -8.05972019e-02,  7.99137455e-01,\n",
       "        7.46505301e-02, -1.83599054e-01, -2.00147518e-01,  4.68818002e-01,\n",
       "       -1.27070351e-02, -3.88554828e-01,  2.42771396e-01,  5.63643658e-01,\n",
       "        1.00692545e+00,  5.65525592e-01,  5.82670010e-01, -1.61572853e-02])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0, 'pca_features'][\"values\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results have the right dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:/home/louberehc/OCR/projets/8_cloud_computing/images_subset/Granadilla/269_100.jpg'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0, 'path']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.  [&#9650;](#toc0_) <a id='toc7_'></a>Compare to not distributed computation based on tf and sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_NON_DIST = './non-distributed-results/'\n",
    "fts_non_dist = pd.read_csv(PATH_NON_DIST + 'fts.csv.gz', index_col=0)\n",
    "scaled_non_dist = pd.read_csv(PATH_NON_DIST + 'scaled.csv.gz', index_col=0)\n",
    "pca_non_dist = pd.read_csv(PATH_NON_DIST + 'pca.csv.gz', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature0</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature1270</th>\n",
       "      <th>feature1271</th>\n",
       "      <th>feature1272</th>\n",
       "      <th>feature1273</th>\n",
       "      <th>feature1274</th>\n",
       "      <th>feature1275</th>\n",
       "      <th>feature1276</th>\n",
       "      <th>feature1277</th>\n",
       "      <th>feature1278</th>\n",
       "      <th>feature1279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/home/louberehc/OCR/projets/8_cloud_computing/images_subset/Kumquats/71_100.jpg</th>\n",
       "      <td>0.036694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005719</td>\n",
       "      <td>0.028472</td>\n",
       "      <td>0.058900</td>\n",
       "      <td>0.028014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003670</td>\n",
       "      <td>0.038330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034528</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/louberehc/OCR/projets/8_cloud_computing/images_subset/Kumquats/r_214_100.jpg</th>\n",
       "      <td>0.309548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.155231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145102</td>\n",
       "      <td>0.039393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030180</td>\n",
       "      <td>0.043894</td>\n",
       "      <td>0.088751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004618</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/louberehc/OCR/projets/8_cloud_computing/images_subset/Kumquats/r_234_100.jpg</th>\n",
       "      <td>0.092173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.620752</td>\n",
       "      <td>0.016290</td>\n",
       "      <td>0.022272</td>\n",
       "      <td>0.025216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.184897</td>\n",
       "      <td>0.013192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/louberehc/OCR/projets/8_cloud_computing/images_subset/Kumquats/r_219_100.jpg</th>\n",
       "      <td>0.327651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.602290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078213</td>\n",
       "      <td>0.032840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.191602</td>\n",
       "      <td>0.023143</td>\n",
       "      <td>0.006719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/louberehc/OCR/projets/8_cloud_computing/images_subset/Kumquats/21_100.jpg</th>\n",
       "      <td>0.294717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023944</td>\n",
       "      <td>0.012229</td>\n",
       "      <td>0.219464</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005253</td>\n",
       "      <td>0.047513</td>\n",
       "      <td>0.179043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134759</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    feature0  feature1  \\\n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.036694       0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.309548       0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.092173       0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.327651       0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.294717       0.0   \n",
       "\n",
       "                                                    feature2  feature3  \\\n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...       0.0       0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...       0.0       0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...       0.0       0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...       0.0       0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...       0.0       0.0   \n",
       "\n",
       "                                                    feature4  feature5  \\\n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.005719  0.028472   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.000009  0.000000   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.000000  0.000000   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.014103  0.000000   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.023944  0.012229   \n",
       "\n",
       "                                                    feature6  feature7  \\\n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.058900  0.028014   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  1.155231  0.000000   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.620752  0.016290   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.602290  0.000000   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.219464  0.019068   \n",
       "\n",
       "                                                    feature8  feature9  ...  \\\n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.000000  0.000000  ...   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.145102  0.039393  ...   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.022272  0.025216  ...   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.078213  0.032840  ...   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.000000  0.000000  ...   \n",
       "\n",
       "                                                    feature1270  feature1271  \\\n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.000000          0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.064710          0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.000000          0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.138702          0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.023362          0.0   \n",
       "\n",
       "                                                    feature1272  feature1273  \\\n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.000000     0.003670   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.000000     0.030180   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.000000     0.000000   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.000000     0.191602   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.005253     0.047513   \n",
       "\n",
       "                                                    feature1274  feature1275  \\\n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.038330     0.000000   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.043894     0.088751   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.184897     0.013192   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.023143     0.006719   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.179043     0.000000   \n",
       "\n",
       "                                                    feature1276  feature1277  \\\n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...          0.0          0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...          0.0          0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...          0.0          0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...          0.0          0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...          0.0          0.0   \n",
       "\n",
       "                                                    feature1278  feature1279  \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.034528          0.0  \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.004618          0.0  \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.000000          0.0  \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.000000          0.0  \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.134759          0.0  \n",
       "\n",
       "[5 rows x 1280 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fts_non_dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "      <th>pca_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>file:/home/louberehc/OCR/projets/8_cloud_compu...</td>\n",
       "      <td>Granadilla</td>\n",
       "      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n",
       "      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>file:/home/louberehc/OCR/projets/8_cloud_compu...</td>\n",
       "      <td>Granadilla</td>\n",
       "      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n",
       "      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>file:/home/louberehc/OCR/projets/8_cloud_compu...</td>\n",
       "      <td>Maracuja</td>\n",
       "      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n",
       "      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>file:/home/louberehc/OCR/projets/8_cloud_compu...</td>\n",
       "      <td>Grape White 3</td>\n",
       "      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n",
       "      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>file:/home/louberehc/OCR/projets/8_cloud_compu...</td>\n",
       "      <td>Maracuja</td>\n",
       "      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n",
       "      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path          label  \\\n",
       "0  file:/home/louberehc/OCR/projets/8_cloud_compu...     Granadilla   \n",
       "1  file:/home/louberehc/OCR/projets/8_cloud_compu...     Granadilla   \n",
       "2  file:/home/louberehc/OCR/projets/8_cloud_compu...       Maracuja   \n",
       "3  file:/home/louberehc/OCR/projets/8_cloud_compu...  Grape White 3   \n",
       "4  file:/home/louberehc/OCR/projets/8_cloud_compu...       Maracuja   \n",
       "\n",
       "                                            features  \\\n",
       "0  {'type': 1, 'size': None, 'indices': None, 'va...   \n",
       "1  {'type': 1, 'size': None, 'indices': None, 'va...   \n",
       "2  {'type': 1, 'size': None, 'indices': None, 'va...   \n",
       "3  {'type': 1, 'size': None, 'indices': None, 'va...   \n",
       "4  {'type': 1, 'size': None, 'indices': None, 'va...   \n",
       "\n",
       "                                        pca_features  \n",
       "0  {'type': 1, 'size': None, 'indices': None, 'va...  \n",
       "1  {'type': 1, 'size': None, 'indices': None, 'va...  \n",
       "2  {'type': 1, 'size': None, 'indices': None, 'va...  \n",
       "3  {'type': 1, 'size': None, 'indices': None, 'va...  \n",
       "4  {'type': 1, 'size': None, 'indices': None, 'va...  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/louberehc/OCR/projets/8_cloud_computing/images_subset/Granadilla/269_100.jpg'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_ = df.loc[0, 'path']\n",
    "c_name_ = name_.removeprefix('file:')\n",
    "c_name_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.04994011, 0.01587156, 0.        , 0.        , 0.        ,\n",
       "       0.92849171, 0.59414637, 0.00505837, 0.2336525 , 0.00953782,\n",
       "       0.02596591, 0.06156127, 0.        , 0.20102984, 0.        ,\n",
       "       0.07110962, 0.        , 0.32307297, 0.01995695, 0.21698575,\n",
       "       0.        , 0.06414215, 0.        , 0.03265156, 0.        ])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fts_ = df.loc[0, 'features']['values']\n",
    "fts_[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8266986 , 0.0335313 , 0.        , 0.        , 0.        ,\n",
       "       1.2652407 , 0.59311146, 0.        , 0.13892299, 0.00309227,\n",
       "       0.06322599, 0.06061769, 0.        , 0.26635894, 0.        ,\n",
       "       0.06027289, 0.        , 0.29231146, 0.00842814, 0.3289087 ,\n",
       "       0.        , 0.10575527, 0.        , 0.04254452, 0.        ])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fts_non_dist.loc[c_name_].values[:25]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are differences, but the magnitude is quite similar and 0 are in the same position.\n",
    "\n",
    "This is mainly due to little differences in the preprocessing stage, supposedly with resampling (see [this notebook](./test-no-distribution.ipynb))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.  [&#9650;](#toc0_) <a id='toc8_'></a>?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 4)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ONLINE_RESULT_PATH = os.getcwd() + '/online_results'\n",
    "dfo = pd.read_parquet(ONLINE_RESULT_PATH, engine='pyarrow')\n",
    "dfo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "50",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/p8_env/lib/python3.10/site-packages/pandas/core/indexes/range.py:345\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 345\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_range\u001b[39m.\u001b[39;49mindex(new_key)\n\u001b[1;32m    346\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "\u001b[0;31mValueError\u001b[0m: 50 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mwhile\u001b[39;00m search:\n\u001b[1;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(n_elem)\n\u001b[0;32m----> 6\u001b[0m     name_ \u001b[39m=\u001b[39m dfo\u001b[39m.\u001b[39;49mloc[n_elem,\u001b[39m'\u001b[39;49m\u001b[39mpath\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m      7\u001b[0m     search_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(name_\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m:])\n\u001b[1;32m      8\u001b[0m     \u001b[39mif\u001b[39;00m fts_non_dist\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mcontains(search_str)\u001b[39m.\u001b[39many():\n",
      "File \u001b[0;32m~/miniconda3/envs/p8_env/lib/python3.10/site-packages/pandas/core/indexing.py:1096\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1094\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(com\u001b[39m.\u001b[39mapply_if_callable(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m key)\n\u001b[1;32m   1095\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m-> 1096\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49m_get_value(\u001b[39m*\u001b[39;49mkey, takeable\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_takeable)\n\u001b[1;32m   1097\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_tuple(key)\n\u001b[1;32m   1098\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1099\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/p8_env/lib/python3.10/site-packages/pandas/core/frame.py:3877\u001b[0m, in \u001b[0;36mDataFrame._get_value\u001b[0;34m(self, index, col, takeable)\u001b[0m\n\u001b[1;32m   3871\u001b[0m engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_engine\n\u001b[1;32m   3873\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, MultiIndex):\n\u001b[1;32m   3874\u001b[0m     \u001b[39m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001b[39;00m\n\u001b[1;32m   3875\u001b[0m     \u001b[39m#  results if our categories are integers that dont match our codes\u001b[39;00m\n\u001b[1;32m   3876\u001b[0m     \u001b[39m# IntervalIndex: IntervalTree has no get_loc\u001b[39;00m\n\u001b[0;32m-> 3877\u001b[0m     row \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(index)\n\u001b[1;32m   3878\u001b[0m     \u001b[39mreturn\u001b[39;00m series\u001b[39m.\u001b[39m_values[row]\n\u001b[1;32m   3880\u001b[0m \u001b[39m# For MultiIndex going through engine effectively restricts us to\u001b[39;00m\n\u001b[1;32m   3881\u001b[0m \u001b[39m#  same-length tuples; see test_get_set_value_no_partial_indexing\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/p8_env/lib/python3.10/site-packages/pandas/core/indexes/range.py:347\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_range\u001b[39m.\u001b[39mindex(new_key)\n\u001b[1;32m    346\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 347\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m    349\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 50"
     ]
    }
   ],
   "source": [
    "search = True\n",
    "n_elem = 0\n",
    "\n",
    "while search:\n",
    "    print(n_elem)\n",
    "    name_ = dfo.loc[n_elem,'path']\n",
    "    search_str = '/'.join(name_.split('/')[-2:])\n",
    "    if fts_non_dist.index.str.contains(search_str).any():\n",
    "        search = False\n",
    "    else:\n",
    "        n_elem += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/louberehc/OCR/projets/8_cloud_computing/images_subset/Kumquats/r_128_100.jpg'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_name_ = (\n",
    "    '/home/louberehc/OCR/projets/8_cloud_computing'\n",
    "    + name_.removeprefix('s3://oc-cloud-computing')\n",
    ")\n",
    "c_name_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature0</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature1270</th>\n",
       "      <th>feature1271</th>\n",
       "      <th>feature1272</th>\n",
       "      <th>feature1273</th>\n",
       "      <th>feature1274</th>\n",
       "      <th>feature1275</th>\n",
       "      <th>feature1276</th>\n",
       "      <th>feature1277</th>\n",
       "      <th>feature1278</th>\n",
       "      <th>feature1279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/home/louberehc/OCR/projets/8_cloud_computing/images_subset/Kumquats/71_100.jpg</th>\n",
       "      <td>0.036694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005719</td>\n",
       "      <td>0.028472</td>\n",
       "      <td>0.058900</td>\n",
       "      <td>0.028014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003670</td>\n",
       "      <td>0.038330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034528</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/louberehc/OCR/projets/8_cloud_computing/images_subset/Kumquats/r_214_100.jpg</th>\n",
       "      <td>0.309548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.155231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145102</td>\n",
       "      <td>0.039393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030180</td>\n",
       "      <td>0.043894</td>\n",
       "      <td>0.088751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004618</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/louberehc/OCR/projets/8_cloud_computing/images_subset/Kumquats/r_234_100.jpg</th>\n",
       "      <td>0.092173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.620752</td>\n",
       "      <td>0.016290</td>\n",
       "      <td>0.022272</td>\n",
       "      <td>0.025216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.184897</td>\n",
       "      <td>0.013192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/louberehc/OCR/projets/8_cloud_computing/images_subset/Kumquats/r_219_100.jpg</th>\n",
       "      <td>0.327651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.602290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078213</td>\n",
       "      <td>0.032840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.191602</td>\n",
       "      <td>0.023143</td>\n",
       "      <td>0.006719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/louberehc/OCR/projets/8_cloud_computing/images_subset/Kumquats/21_100.jpg</th>\n",
       "      <td>0.294717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023944</td>\n",
       "      <td>0.012229</td>\n",
       "      <td>0.219464</td>\n",
       "      <td>0.019068</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005253</td>\n",
       "      <td>0.047513</td>\n",
       "      <td>0.179043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134759</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/louberehc/OCR/projets/8_cloud_computing/images_subset/Kumquats/r_123_100.jpg</th>\n",
       "      <td>0.252187</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068111</td>\n",
       "      <td>0.075082</td>\n",
       "      <td>0.531213</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065831</td>\n",
       "      <td>0.015173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007191</td>\n",
       "      <td>0.528919</td>\n",
       "      <td>0.379969</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.238630</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/louberehc/OCR/projets/8_cloud_computing/images_subset/Kumquats/r_316_100.jpg</th>\n",
       "      <td>0.857297</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.256253</td>\n",
       "      <td>0.213074</td>\n",
       "      <td>0.004844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026232</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.047997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/louberehc/OCR/projets/8_cloud_computing/images_subset/Kumquats/r_19_100.jpg</th>\n",
       "      <td>0.555136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005636</td>\n",
       "      <td>1.329911</td>\n",
       "      <td>0.204190</td>\n",
       "      <td>0.014705</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015190</td>\n",
       "      <td>0.023478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/louberehc/OCR/projets/8_cloud_computing/images_subset/Kumquats/162_100.jpg</th>\n",
       "      <td>0.253767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026469</td>\n",
       "      <td>0.012183</td>\n",
       "      <td>0.612994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.162961</td>\n",
       "      <td>0.169570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045466</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/louberehc/OCR/projets/8_cloud_computing/images_subset/Kumquats/r_65_100.jpg</th>\n",
       "      <td>0.647553</td>\n",
       "      <td>0.013179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.535789</td>\n",
       "      <td>0.009908</td>\n",
       "      <td>0.147036</td>\n",
       "      <td>0.021713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175637</td>\n",
       "      <td>0.002533</td>\n",
       "      <td>0.101531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033047</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 1280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    feature0  feature1  \\\n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.036694  0.000000   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.309548  0.000000   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.092173  0.000000   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.327651  0.000000   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.294717  0.000000   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.252187  0.000000   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.857297  0.000997   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.555136  0.000000   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.253767  0.000000   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.647553  0.013179   \n",
       "\n",
       "                                                    feature2  feature3  \\\n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...       0.0       0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...       0.0       0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...       0.0       0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...       0.0       0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...       0.0       0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...       0.0       0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...       0.0       0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...       0.0       0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...       0.0       0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...       0.0       0.0   \n",
       "\n",
       "                                                    feature4  feature5  \\\n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.005719  0.028472   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.000009  0.000000   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.000000  0.000000   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.014103  0.000000   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.023944  0.012229   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.068111  0.075082   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.001122  0.000000   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.000000  0.005636   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.026469  0.012183   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.007197  0.000000   \n",
       "\n",
       "                                                    feature6  feature7  \\\n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.058900  0.028014   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  1.155231  0.000000   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.620752  0.016290   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.602290  0.000000   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.219464  0.019068   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.531213  0.000000   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  1.256253  0.213074   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  1.329911  0.204190   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.612994  0.000000   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.535789  0.009908   \n",
       "\n",
       "                                                    feature8  feature9  ...  \\\n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.000000  0.000000  ...   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.145102  0.039393  ...   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.022272  0.025216  ...   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.078213  0.032840  ...   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.000000  0.000000  ...   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.065831  0.015173  ...   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.004844  0.000000  ...   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.014705  0.000000  ...   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.000000  0.005717  ...   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...  0.147036  0.021713  ...   \n",
       "\n",
       "                                                    feature1270  feature1271  \\\n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.000000          0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.064710          0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.000000          0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.138702          0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.023362          0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.000000          0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.000000          0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.000000          0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.017938          0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.000752          0.0   \n",
       "\n",
       "                                                    feature1272  feature1273  \\\n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.000000     0.003670   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.000000     0.030180   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.000000     0.000000   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.000000     0.191602   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.005253     0.047513   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.007191     0.528919   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.000000     0.026232   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.000000     0.015190   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.000000     0.162961   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.000000     0.175637   \n",
       "\n",
       "                                                    feature1274  feature1275  \\\n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.038330     0.000000   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.043894     0.088751   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.184897     0.013192   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.023143     0.006719   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.179043     0.000000   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.379969     0.000000   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.034188     0.047997   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.023478     0.000000   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.169570     0.000000   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.002533     0.101531   \n",
       "\n",
       "                                                    feature1276  feature1277  \\\n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...          0.0          0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...          0.0          0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...          0.0          0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...          0.0          0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...          0.0          0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...          0.0          0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...          0.0          0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...          0.0          0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...          0.0          0.0   \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...          0.0          0.0   \n",
       "\n",
       "                                                    feature1278  feature1279  \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.034528          0.0  \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.004618          0.0  \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.000000          0.0  \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.000000          0.0  \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.134759          0.0  \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.238630          0.0  \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.000000          0.0  \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.000000          0.0  \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.045466          0.0  \n",
       "/home/louberehc/OCR/projets/8_cloud_computing/i...     0.033047          0.0  \n",
       "\n",
       "[10 rows x 1280 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fts_non_dist.loc[fts_non_dist.index.str.contains('Kumquats')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
